{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from agents.general_agent import Agent\n",
    "from agents.seminal_eval_agent import SeminalEvalAgent\n",
    "from agents.concept_extraction_agent import ConceptExtractionAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting concepts from the project...\n",
      "Concepts and Metadata:\n",
      " {\n",
      "    \"project_title\": \"Robotic Object Manipulation in Unstructured Environments\",\n",
      "    \"project_summary\": \"This project involves developing a robotic system that learns to manipulate objects in unstructured environments using reinforcement learning. The system aims to generalize manipulation skills to novel objects and situations by processing visual input, planning grasping strategies, and executing tasks.\",\n",
      "    \"prerequisites\": [\"Basic programming skills\", \"Familiarity with Python\", \"Linear algebra\"],\n",
      "    \"fundamental_concepts\": [\"Machine Learning\", \"Robotic Kinematics\", \"Control Theory\"],\n",
      "    \"core_concepts\": [\"Reinforcement Learning\", \"Robotics\", \"Computer Vision\"],\n",
      "    \"specialized_concepts\": [\"RL for Grasping Strategies\", \"Sim-to-Real Transfer\", \"Affordance-Based Manipulation\"]\n",
      "}\n",
      "Concepts and Metadata:\n",
      " {\n",
      "    \"project_title\": \"Robotic Object Manipulation in Unstructured Environments\",\n",
      "    \"project_summary\": \"This project involves developing a robotic system that learns to manipulate objects in unstructured environments using reinforcement learning. The system aims to generalize manipulation skills to novel objects and situations by processing visual input, planning grasping strategies, and executing tasks.\",\n",
      "    \"prerequisites\": [\"Basic programming skills\", \"Familiarity with Python\", \"Linear algebra\"],\n",
      "    \"fundamental_concepts\": [\"Machine Learning\", \"Robotic Kinematics\", \"Control Theory\"],\n",
      "    \"core_concepts\": [\"Reinforcement Learning\", \"Robotics\", \"Computer Vision\"],\n",
      "    \"specialized_concepts\": [\"RL for Grasping Strategies\", \"Sim-to-Real Transfer\", \"Affordance-Based Manipulation\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "queries_folder = os.path.join(notebook_dir, \"..\", \"queries\")\n",
    "\n",
    "gpt_agent = Agent(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "concept_agent = ConceptExtractionAgent(gpt_agent, queries_folder=queries_folder)\n",
    "\n",
    "project = \"robotics\"\n",
    "\n",
    "try:\n",
    "    print(\"Extracting concepts from the project...\")\n",
    "    response = concept_agent.extract_concepts(f\"{project}.json\")\n",
    "    project_title = response[\"project_title\"]\n",
    "    project_summary = response[\"project_summary\"]\n",
    "    \n",
    "    core_concepts = response[\"core_concepts\"]\n",
    "    specialized_concepts = response[\"specialized_concepts\"]\n",
    "    fundamental_concepts = response[\"fundamental_concepts\"]\n",
    "    prerequisites = response[\"prerequisites\"]\n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surveying for papers...\n",
      "Survey papers for Computer Vision:\n",
      "{\n",
      "    \"papers\": [\n",
      "        {\n",
      "            \"title\": \"Deep Learning for Computer Vision: A Brief Review\",\n",
      "            \"authors\": [\n",
      "                \"A. Krizhevsky\",\n",
      "                \"I. Sutskever\",\n",
      "                \"G. E. Hinton\"\n",
      "            ],\n",
      "            \"journal\": \"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\n",
      "            \"year\": 2017,\n",
      "            \"doi\": \"10.1109/TPAMI.2017.2655023\",\n",
      "            \"url\": \"https://ieeexplore.ieee.org/document/2655023\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey on Image Data Augmentation for Deep Learning\",\n",
      "            \"authors\": [\n",
      "                \"M. Shorten\",\n",
      "                \"T. M. Khoshgoftaar\"\n",
      "            ],\n",
      "            \"journal\": \"Journal of Big Data\",\n",
      "            \"year\": 2019,\n",
      "            \"doi\": \"10.1186/s40537-019-0197-0\",\n",
      "            \"url\": \"https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Comprehensive Review on Image Dehazing Algorithms\",\n",
      "            \"authors\": [\n",
      "                \"S. Anwar\",\n",
      "                \"C. Li\",\n",
      "                \"F. Porikli\"\n",
      "            ],\n",
      "            \"journal\": \"IEEE Transactions on Intelligent Transportation Systems\",\n",
      "            \"year\": 2020,\n",
      "            \"doi\": \"10.1109/TITS.2020.2973561\",\n",
      "            \"url\": \"https://ieeexplore.ieee.org/document/2973561\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey on Visual Transformer Models\",\n",
      "            \"authors\": [\n",
      "                \"A. Dosovitskiy\",\n",
      "                \"L. Beyer\",\n",
      "                \"A. Kolesnikov\"\n",
      "            ],\n",
      "            \"journal\": \"arXiv preprint\",\n",
      "            \"year\": 2021,\n",
      "            \"doi\": \"10.48550/arXiv.2103.15808\",\n",
      "            \"url\": \"https://arxiv.org/abs/2103.15808\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey on Object Detection in Aerial Images\",\n",
      "            \"authors\": [\n",
      "                \"X. Li\",\n",
      "                \"H. Zhao\",\n",
      "                \"X. Lu\"\n",
      "            ],\n",
      "            \"journal\": \"IEEE Transactions on Geoscience and Remote Sensing\",\n",
      "            \"year\": 2021,\n",
      "            \"doi\": \"10.1109/TGRS.2021.3058584\",\n",
      "            \"url\": \"https://ieeexplore.ieee.org/document/3058584\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey on 3D Shape Analysis\",\n",
      "            \"authors\": [\n",
      "                \"S. Biasotti\",\n",
      "                \"A. Cerri\",\n",
      "                \"P. Frosini\"\n",
      "            ],\n",
      "            \"journal\": \"Computer Graphics Forum\",\n",
      "            \"year\": 2016,\n",
      "            \"doi\": \"10.1111/cgf.12878\",\n",
      "            \"url\": \"https://onlinelibrary.wiley.com/doi/10.1111/cgf.12878\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Survey papers for Reinforcement Learning:\n",
      "{\n",
      "    \"papers\": [\n",
      "        {\n",
      "            \"title\": \"A Survey on Reinforcement Learning: Open Problems and Applications\",\n",
      "            \"authors\": [\n",
      "                \"Yuxi Li\"\n",
      "            ],\n",
      "            \"journal\": \"Journal of Artificial Intelligence Research\",\n",
      "            \"year\": 2018,\n",
      "            \"doi\": \"10.1613/jair.1.11266\",\n",
      "            \"url\": \"https://www.jair.org/index.php/jair/article/view/11266\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Deep Reinforcement Learning: A Survey\",\n",
      "            \"authors\": [\n",
      "                \"Yuxi Li\"\n",
      "            ],\n",
      "            \"journal\": \"arXiv preprint arXiv:1701.07274\",\n",
      "            \"year\": 2017,\n",
      "            \"doi\": \"10.48550/arXiv.1701.07274\",\n",
      "            \"url\": \"https://arxiv.org/abs/1701.07274\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey of Reinforcement Learning Informed by Natural Language\",\n",
      "            \"authors\": [\n",
      "                \"Felix Hill\",\n",
      "                \"Stephen Clark\"\n",
      "            ],\n",
      "            \"journal\": \"arXiv preprint arXiv:1906.03926\",\n",
      "            \"year\": 2019,\n",
      "            \"doi\": \"10.48550/arXiv.1906.03926\",\n",
      "            \"url\": \"https://arxiv.org/abs/1906.03926\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey of Safe Reinforcement Learning: Methods, Theory and Applications\",\n",
      "            \"authors\": [\n",
      "                \"Bruno C. da Silva\",\n",
      "                \"Guilherme Neumann\",\n",
      "                \"Marc G. Bellemare\"\n",
      "            ],\n",
      "            \"journal\": \"arXiv preprint arXiv:2105.04819\",\n",
      "            \"year\": 2021,\n",
      "            \"doi\": \"10.48550/arXiv.2105.04819\",\n",
      "            \"url\": \"https://arxiv.org/abs/2105.04819\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey on Policy Search for Robotics\",\n",
      "            \"authors\": [\n",
      "                \"Jens Kober\",\n",
      "                \"J. Andrew Bagnell\",\n",
      "                \"Jan Peters\"\n",
      "            ],\n",
      "            \"journal\": \"Foundations and Trends in Robotics\",\n",
      "            \"year\": 2013,\n",
      "            \"doi\": \"10.1561/2300000021\",\n",
      "            \"url\": \"https://www.nowpublishers.com/article/Details/ROB-021\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey of Inverse Reinforcement Learning: Challenges, Methods and Progress\",\n",
      "            \"authors\": [\n",
      "                \"Ziyu Wan\",\n",
      "                \"Tianyang Yu\",\n",
      "                \"Yuke Zhu\"\n",
      "            ],\n",
      "            \"journal\": \"arXiv preprint arXiv:2006.15438\",\n",
      "            \"year\": 2020,\n",
      "            \"doi\": \"10.48550/arXiv.2006.15438\",\n",
      "            \"url\": \"https://arxiv.org/abs/2006.15438\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Survey papers for Robotics:\n",
      "{\n",
      "    \"papers\": [\n",
      "        {\n",
      "            \"title\": \"A Survey of Robot Learning from Demonstration\",\n",
      "            \"authors\": [\n",
      "                \"Brenna D. Argall\",\n",
      "                \"Sonia Chernova\",\n",
      "                \"Manuela Veloso\",\n",
      "                \"Brett Browning\"\n",
      "            ],\n",
      "            \"journal\": \"Robotics and Autonomous Systems\",\n",
      "            \"year\": 2009,\n",
      "            \"doi\": \"10.1016/j.robot.2008.10.024\",\n",
      "            \"url\": \"https://www.sciencedirect.com/science/article/pii/S0921889008001772\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey of Motion Planning and Control Techniques for Self-driving Urban Vehicles\",\n",
      "            \"authors\": [\n",
      "                \"Bojun Shi\",\n",
      "                \"Jianqiang Wang\",\n",
      "                \"Chengcheng Xu\",\n",
      "                \"Jianru Xue\",\n",
      "                \"Nanning Zheng\"\n",
      "            ],\n",
      "            \"journal\": \"IEEE Transactions on Intelligent Transportation Systems\",\n",
      "            \"year\": 2020,\n",
      "            \"doi\": \"10.1109/TITS.2019.2908801\",\n",
      "            \"url\": \"https://ieeexplore.ieee.org/document/8685325\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey of Robot Policy Learning: Representations, Algorithms, and Challenges\",\n",
      "            \"authors\": [\n",
      "                \"Yan Duan\",\n",
      "                \"Pieter Abbeel\"\n",
      "            ],\n",
      "            \"journal\": \"arXiv\",\n",
      "            \"year\": 2018,\n",
      "            \"doi\": \"10.48550/arXiv.1806.02952\",\n",
      "            \"url\": \"https://arxiv.org/abs/1806.02952\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey of Robotic Manipulation: Challenges, Methods, and Future Directions\",\n",
      "            \"authors\": [\n",
      "                \"Matei Ciocarlie\",\n",
      "                \"Katherine J. Kuchenbecker\"\n",
      "            ],\n",
      "            \"journal\": \"Annual Review of Control, Robotics, and Autonomous Systems\",\n",
      "            \"year\": 2020,\n",
      "            \"doi\": \"10.1146/annurev-control-060117-105003\",\n",
      "            \"url\": \"https://www.annualreviews.org/doi/10.1146/annurev-control-060117-105003\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey of Robot Localization and Mapping: From Personal Assistance to Planetary Exploration\",\n",
      "            \"authors\": [\n",
      "                \"Cyrill Stachniss\",\n",
      "                \"Giorgio Grisetti\",\n",
      "                \"Wolfram Burgard\"\n",
      "            ],\n",
      "            \"journal\": \"Robotics and Autonomous Systems\",\n",
      "            \"year\": 2016,\n",
      "            \"doi\": \"10.1016/j.robot.2016.01.011\",\n",
      "            \"url\": \"https://www.sciencedirect.com/science/article/pii/S0921889016000115\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey of Robot Operating System: Concepts, Tools, and Challenges\",\n",
      "            \"authors\": [\n",
      "                \"Anis Koubaa\"\n",
      "            ],\n",
      "            \"journal\": \"Springer\",\n",
      "            \"year\": 2016,\n",
      "            \"doi\": \"10.1007/978-3-319-26054-9_1\",\n",
      "            \"url\": \"https://link.springer.com/chapter/10.1007/978-3-319-26054-9_1\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "Survey Papers:\n",
      "\n",
      "Concept: Reinforcement Learning\n",
      "- A Survey on Reinforcement Learning: Open Problems and Applications\n",
      "- Deep Reinforcement Learning: A Survey\n",
      "- A Survey of Reinforcement Learning Informed by Natural Language\n",
      "- A Survey of Safe Reinforcement Learning: Methods, Theory and Applications\n",
      "- A Survey on Policy Search for Robotics\n",
      "- A Survey of Inverse Reinforcement Learning: Challenges, Methods and Progress\n",
      "\n",
      "Concept: Robotics\n",
      "- A Survey of Robot Learning from Demonstration\n",
      "- A Survey of Motion Planning and Control Techniques for Self-driving Urban Vehicles\n",
      "- A Survey of Robot Policy Learning: Representations, Algorithms, and Challenges\n",
      "- A Survey of Robotic Manipulation: Challenges, Methods, and Future Directions\n",
      "- A Survey of Robot Localization and Mapping: From Personal Assistance to Planetary Exploration\n",
      "- A Survey of Robot Operating System: Concepts, Tools, and Challenges\n",
      "\n",
      "Concept: Computer Vision\n",
      "- Deep Learning for Computer Vision: A Brief Review\n",
      "- A Survey on Image Data Augmentation for Deep Learning\n",
      "- A Comprehensive Review on Image Dehazing Algorithms\n",
      "- A Survey on Visual Transformer Models\n",
      "- A Survey on Object Detection in Aerial Images\n",
      "- A Survey on 3D Shape Analysis\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Query for survey papers for each core concept\n",
    "survey_papers = {}\n",
    "\n",
    "def find_survey_papers(concept):\n",
    "    \"\"\"\n",
    "    Query the agent for seminal papers for a given concept.\n",
    "    \"\"\"\n",
    "    input_text = f\"\"\"\n",
    "    Provide 6 survey papers on the topic '{concept}' along with their DOI id's, URLs, and other metadata in the following JSON format.\n",
    "    Do NOT include tick marks or any other formatting. Just ONLY provide the JSON object: \n",
    "    {{\n",
    "        \"papers\": [\n",
    "            {{\n",
    "                \"title\": \"<title>\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        gpt_response = gpt_agent.query(\"You are a helpful assistant.\", input_text)\n",
    "        print(f\"Survey papers for {concept}:\\n{json.dumps(json.loads(gpt_response), indent=4)}\")\n",
    "        return concept, json.loads(gpt_response)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Failed to parse GPT-4 response for {concept}. Response: {gpt_response}\")\n",
    "        return concept, []\n",
    "\n",
    "# Parallelize the process of querying for survey papers\n",
    "print(\"Surveying for papers...\")\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future_to_concept = {executor.submit(find_survey_papers, concept): concept for concept in core_concepts}\n",
    "    for future in future_to_concept:\n",
    "        concept, papers = future.result()\n",
    "        survey_papers[concept] = papers\n",
    "\n",
    "# Output the survey papers\n",
    "print(\"\\nSurvey Papers:\")\n",
    "for concept, papers in survey_papers.items():\n",
    "    print(f\"\\nConcept: {concept}\")\n",
    "    for paper in papers.get(\"papers\", []):\n",
    "        print(f\"- {paper['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seminal Paper Counts by Topic:\n",
      "\n",
      "Concept: Reinforcement Learning\n",
      "Reinforcement Learning: An Introduction: 6\n",
      "Asynchronous Methods for Deep Reinforcement Learning: 2\n",
      "Playing Atari with Deep Reinforcement Learning: 2\n",
      "Human-level Control through Deep Reinforcement Learning: 2\n",
      "Deep Reinforcement Learning with Double Q-learning: 2\n",
      "Algorithms for Reinforcement Learning: 2\n",
      "Human-level control through deep reinforcement learning: 1\n",
      "Proximal Policy Optimization Algorithms: 1\n",
      "A Survey of Reinforcement Learning Algorithms: 1\n",
      "Dynamic Programming and Optimal Control: 1\n",
      "Deep Reinforcement Learning with Dynamic Environments: 1\n",
      "Adaptive Reinforcement Learning in Non-Stationary Environments: 1\n",
      "Temporal Difference Learning and TD-Gammon: 1\n",
      "Policy Gradient Methods for Reinforcement Learning with Function Approximation: 1\n",
      "Multi-Agent Systems: Algorithmic, Game-Theoretic, and Logical Foundations: 1\n",
      "Cooperative Multi-Agent Reinforcement Learning: A Survey: 1\n",
      "Model-Based Reinforcement Learning: A Survey: 1\n",
      "Dyna: An Integrated Architecture for Learning, Planning, and Reacting: 1\n",
      "Efficient Exploration in Reinforcement Learning: 1\n",
      "AlphaGo Zero: Mastering the Game of Go without Human Knowledge: 1\n",
      "\n",
      "Concept: Robotics\n",
      "Principles of Robot Motion: Theory, Algorithms, and Implementations: 3\n",
      "Robotics in Food Processing: An Overview: 1\n",
      "Automation Technologies for the Food Industry: 1\n",
      "Advances in Food Robotics: 1\n",
      "Innovations in Food Manufacturing Automation: 1\n",
      "The Role of Robotics in Modern Food Production: 1\n",
      "Programming by Demonstration: A Method for Robot Programming: 1\n",
      "Learning from Demonstration: 1\n",
      "Robot Learning from Demonstration: 1\n",
      "Imitation Learning: A Survey of Learning Methods: 1\n",
      "Deep Learning for Robot Learning from Demonstration: 1\n",
      "Probabilistic Robotics: 1\n",
      "Mobile Robot Localization Using Particle Filters: 1\n",
      "Monte Carlo Localization: Efficient Position Estimation for Mobile Robots: 1\n",
      "A Survey of Simultaneous Localization and Mapping (SLAM) Algorithms: 1\n",
      "Introduction to Autonomous Mobile Robots: 1\n",
      "Introduction to Robotics: Mechanics and Control: 1\n",
      "Robot Programming: A Practical Guide to Behavior-Based Robotics: 1\n",
      "Programming Robots with ROS: 1\n",
      "Robot Operating System (ROS): The Complete Reference: 1\n",
      "Robot Manipulation: Mathematics, Algorithms, and Applications: 1\n",
      "Modern Robotics: Mechanics, Planning, and Control: 1\n",
      "Robotic Grasping and Fine Manipulation: 1\n",
      "Learning for Robot Manipulation: 1\n",
      "Cooperative Control of Multi-Robot Systems: 1\n",
      "Distributed Algorithms for Multi-Robot Systems: 1\n",
      "Swarm Robotics: From Inspiration to Applications: 1\n",
      "Multi-Robot Systems: From Swarms to Intelligent Automata: 1\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Separate dictionaries for seminal paper counts by topic\n",
    "seminal_paper_counts_by_topic = {}\n",
    "top_references = {}\n",
    "\n",
    "def find_seminal_works(concept, paper):\n",
    "    \"\"\"\n",
    "    Query the agent for the 5 most seminal works for a given paper.\n",
    "    \"\"\"\n",
    "    title = paper.get(\"title\", \"Unknown Title\")\n",
    "    input_text = f\"\"\"\n",
    "    For the paper titled '{title}', provide the 5 most seminal works (including papers and textbooks) in the field that are related to this paper and would likely be cited. \n",
    "    If you cannot access external databases, respond with 5 hypothetical seminal works based on the paper title in the following example JSON format (not with this content, but with the same structure):\n",
    "    Do NOT include tick marks or any other formatting. Just ONLY provide the JSON object: \n",
    "    {{\n",
    "        \"seminal_works\": [\n",
    "            {{\"title\": \"Seminal Work 1\", \"year\": 1998}},\n",
    "            {{\"title\": \"Seminal Work 2\", \"year\": 2013}},\n",
    "            {{\"title\": \"Seminal Work 3\", \"year\": 2015}},\n",
    "            {{\"title\": \"Seminal Work 4\", \"year\": 2020}},\n",
    "            {{\"title\": \"Seminal Work 5\", \"year\": 2021}}\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        gpt_response = gpt_agent.query(\"You are a helpful assistant.\", input_text)\n",
    "        references = json.loads(gpt_response).get(\"seminal_works\", [])\n",
    "        return concept, title, references\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Failed to parse GPT-4 response for paper: {title}\")\n",
    "        return concept, title, []\n",
    "\n",
    "# Parallelize the process of querying for seminal works\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future_to_paper = {\n",
    "        executor.submit(find_seminal_works, concept, paper): (concept, paper)\n",
    "        for concept, papers in survey_papers.items()\n",
    "        for paper in papers.get(\"papers\", [])\n",
    "    }\n",
    "    for future in future_to_paper:\n",
    "        concept, title, references = future.result()\n",
    "        if concept not in top_references:\n",
    "            top_references[concept] = {}\n",
    "        if concept not in seminal_paper_counts_by_topic:\n",
    "            seminal_paper_counts_by_topic[concept] = {}\n",
    "\n",
    "        top_references[concept][title] = references\n",
    "        for ref in references:\n",
    "            ref_title = ref[\"title\"]\n",
    "            if ref_title in seminal_paper_counts_by_topic[concept]:\n",
    "                seminal_paper_counts_by_topic[concept][ref_title] += 1\n",
    "            else:\n",
    "                seminal_paper_counts_by_topic[concept][ref_title] = 1\n",
    "\n",
    "# Output the seminal paper counts for each topic\n",
    "print(\"\\nSeminal Paper Counts by Topic:\")\n",
    "for concept, counts in seminal_paper_counts_by_topic.items():\n",
    "    print(f\"\\nConcept: {concept}\")\n",
    "    sorted_counts = sorted(counts.items(), key=lambda item: item[1], reverse=True)\n",
    "    for paper_title, count in sorted_counts:\n",
    "        print(f\"{paper_title}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 'Reinforcement Learning': High-count papers selected: ['Reinforcement Learning: An Introduction', 'Asynchronous Methods for Deep Reinforcement Learning', 'Playing Atari with Deep Reinforcement Learning', 'Human-level Control through Deep Reinforcement Learning', 'Deep Reinforcement Learning with Double Q-learning', 'Algorithms for Reinforcement Learning']\n",
      "Topic 'Reinforcement Learning': Final selected papers: ['Reinforcement Learning: An Introduction', 'Asynchronous Methods for Deep Reinforcement Learning', 'Playing Atari with Deep Reinforcement Learning', 'Human-level Control through Deep Reinforcement Learning', 'Deep Reinforcement Learning with Double Q-learning', 'Algorithms for Reinforcement Learning', 'Human-level control through deep reinforcement learning', 'Proximal Policy Optimization Algorithms', 'Deep Reinforcement Learning with Dynamic Environments', 'Adaptive Reinforcement Learning in Non-Stationary Environments', 'Model-Based Reinforcement Learning: A Survey', 'Efficient Exploration in Reinforcement Learning']\n",
      "Topic 'Robotics': High-count papers selected: ['Principles of Robot Motion: Theory, Algorithms, and Implementations']\n",
      "Topic 'Reinforcement Learning': Final selected papers: ['Reinforcement Learning: An Introduction', 'Asynchronous Methods for Deep Reinforcement Learning', 'Playing Atari with Deep Reinforcement Learning', 'Human-level Control through Deep Reinforcement Learning', 'Deep Reinforcement Learning with Double Q-learning', 'Algorithms for Reinforcement Learning', 'Human-level control through deep reinforcement learning', 'Proximal Policy Optimization Algorithms', 'Deep Reinforcement Learning with Dynamic Environments', 'Adaptive Reinforcement Learning in Non-Stationary Environments', 'Model-Based Reinforcement Learning: A Survey', 'Efficient Exploration in Reinforcement Learning']\n",
      "Topic 'Robotics': High-count papers selected: ['Principles of Robot Motion: Theory, Algorithms, and Implementations']\n",
      "Topic 'Robotics': Final selected papers: ['Principles of Robot Motion: Theory, Algorithms, and Implementations', 'Learning for Robot Manipulation', 'Robot Manipulation: Mathematics, Algorithms, and Applications', 'Robotic Grasping and Fine Manipulation', 'Deep Learning for Robot Learning from Demonstration', 'Robot Learning from Demonstration', 'Imitation Learning: A Survey of Learning Methods']\n",
      "\n",
      "Selected Papers for Evaluation:\n",
      "\n",
      "Topic: Reinforcement Learning\n",
      "- Reinforcement Learning: An Introduction\n",
      "- Asynchronous Methods for Deep Reinforcement Learning\n",
      "- Playing Atari with Deep Reinforcement Learning\n",
      "- Human-level Control through Deep Reinforcement Learning\n",
      "- Deep Reinforcement Learning with Double Q-learning\n",
      "- Algorithms for Reinforcement Learning\n",
      "- Human-level control through deep reinforcement learning\n",
      "- Proximal Policy Optimization Algorithms\n",
      "- Deep Reinforcement Learning with Dynamic Environments\n",
      "- Adaptive Reinforcement Learning in Non-Stationary Environments\n",
      "- Model-Based Reinforcement Learning: A Survey\n",
      "- Efficient Exploration in Reinforcement Learning\n",
      "\n",
      "Topic: Robotics\n",
      "- Principles of Robot Motion: Theory, Algorithms, and Implementations\n",
      "- Learning for Robot Manipulation\n",
      "- Robot Manipulation: Mathematics, Algorithms, and Applications\n",
      "- Robotic Grasping and Fine Manipulation\n",
      "- Deep Learning for Robot Learning from Demonstration\n",
      "- Robot Learning from Demonstration\n",
      "- Imitation Learning: A Survey of Learning Methods\n",
      "Topic 'Robotics': Final selected papers: ['Principles of Robot Motion: Theory, Algorithms, and Implementations', 'Learning for Robot Manipulation', 'Robot Manipulation: Mathematics, Algorithms, and Applications', 'Robotic Grasping and Fine Manipulation', 'Deep Learning for Robot Learning from Demonstration', 'Robot Learning from Demonstration', 'Imitation Learning: A Survey of Learning Methods']\n",
      "\n",
      "Selected Papers for Evaluation:\n",
      "\n",
      "Topic: Reinforcement Learning\n",
      "- Reinforcement Learning: An Introduction\n",
      "- Asynchronous Methods for Deep Reinforcement Learning\n",
      "- Playing Atari with Deep Reinforcement Learning\n",
      "- Human-level Control through Deep Reinforcement Learning\n",
      "- Deep Reinforcement Learning with Double Q-learning\n",
      "- Algorithms for Reinforcement Learning\n",
      "- Human-level control through deep reinforcement learning\n",
      "- Proximal Policy Optimization Algorithms\n",
      "- Deep Reinforcement Learning with Dynamic Environments\n",
      "- Adaptive Reinforcement Learning in Non-Stationary Environments\n",
      "- Model-Based Reinforcement Learning: A Survey\n",
      "- Efficient Exploration in Reinforcement Learning\n",
      "\n",
      "Topic: Robotics\n",
      "- Principles of Robot Motion: Theory, Algorithms, and Implementations\n",
      "- Learning for Robot Manipulation\n",
      "- Robot Manipulation: Mathematics, Algorithms, and Applications\n",
      "- Robotic Grasping and Fine Manipulation\n",
      "- Deep Learning for Robot Learning from Demonstration\n",
      "- Robot Learning from Demonstration\n",
      "- Imitation Learning: A Survey of Learning Methods\n"
     ]
    }
   ],
   "source": [
    "# Initialize the evaluation agent\n",
    "seminal_eval_agent = SeminalEvalAgent(seminal_paper_counts_by_topic, gpt_agent, project_summary)\n",
    "\n",
    "# Select papers based on the criteria\n",
    "selected_papers = seminal_eval_agent.select_papers()\n",
    "\n",
    "# Output the selected papers for evaluation\n",
    "print(\"\\nSelected Papers for Evaluation:\")\n",
    "for topic, papers in selected_papers.items():\n",
    "    print(f\"\\nTopic: {topic}\")\n",
    "    for paper in papers:\n",
    "        print(f\"- {paper}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for paper 'Asynchronous Methods for Deep Reinforcement Learning': yes\n",
      "Response for paper 'Reinforcement Learning: An Introduction': yes\n",
      "Response for paper 'Proximal Policy Optimization Algorithms': yes\n",
      "Response for paper 'Model-Based Reinforcement Learning: A Survey': yes\n",
      "Response for paper 'Deep Reinforcement Learning with Dynamic Environments': no\n",
      "Response for paper 'Deep Reinforcement Learning with Double Q-learning': yes\n",
      "Response for paper 'Efficient Exploration in Reinforcement Learning': yes\n",
      "Response for paper 'Adaptive Reinforcement Learning in Non-Stationary Environments': no\n",
      "Response for paper 'Deep Reinforcement Learning with Dynamic Environments': no\n",
      "Response for paper 'Deep Reinforcement Learning with Double Q-learning': yes\n",
      "Response for paper 'Efficient Exploration in Reinforcement Learning': yes\n",
      "Response for paper 'Adaptive Reinforcement Learning in Non-Stationary Environments': no\n",
      "Response for paper 'Human-level Control through Deep Reinforcement Learning': yes\n",
      "Response for paper 'Algorithms for Reinforcement Learning': yes\n",
      "Response for paper 'Human-level Control through Deep Reinforcement Learning': yes\n",
      "Response for paper 'Algorithms for Reinforcement Learning': yes\n",
      "Response for paper 'Human-level control through deep reinforcement learning': yes\n",
      "Response for paper 'Human-level control through deep reinforcement learning': yes\n",
      "Response for paper 'Playing Atari with Deep Reinforcement Learning': yes\n",
      "Response for paper 'Playing Atari with Deep Reinforcement Learning': yes\n",
      "Response for paper 'Learning for Robot Manipulation': yes\n",
      "Response for paper 'Principles of Robot Motion: Theory, Algorithms, and Implementations': yes\n",
      "Response for paper 'Robot Manipulation: Mathematics, Algorithms, and Applications': yes\n",
      "Response for paper 'Robot Learning from Demonstration': yes\n",
      "Response for paper 'Imitation Learning: A Survey of Learning Methods': no\n",
      "Response for paper 'Deep Learning for Robot Learning from Demonstration': yes\n",
      "Response for paper 'Learning for Robot Manipulation': yes\n",
      "Response for paper 'Principles of Robot Motion: Theory, Algorithms, and Implementations': yes\n",
      "Response for paper 'Robot Manipulation: Mathematics, Algorithms, and Applications': yes\n",
      "Response for paper 'Robot Learning from Demonstration': yes\n",
      "Response for paper 'Imitation Learning: A Survey of Learning Methods': no\n",
      "Response for paper 'Deep Learning for Robot Learning from Demonstration': yes\n",
      "Response for paper 'Robotic Grasping and Fine Manipulation': yes\n",
      "Response for paper 'Robotic Grasping and Fine Manipulation': yes\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Prune evaluation papers using specialized topics\n",
    "def prune_papers(specialized_topics, evaluation_papers):\n",
    "    \"\"\"\n",
    "    Use an LLM agent to filter evaluation papers based on specialized topics.\n",
    "    \"\"\"\n",
    "    pruned_papers = {}\n",
    "\n",
    "    def process_paper(topic, paper):\n",
    "        input_text = f\"\"\"\n",
    "        The project focuses on the following specialized topics: {', '.join(specialized_topics)}.\n",
    "        Determine if the paper titled '{paper}' is directly relevant and truly essential to either one of these:\n",
    "        1. general understanding of {topic}\n",
    "        2. the project: {project_summary}.\n",
    "\n",
    "        Respond with ONLY the word \"yes\" (nothing other than the word) if it is relevant or beneficial to understanding the topic in general.\n",
    "        Otherwise respond with ONLY the word \"no\" (nothing other than the word).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = gpt_agent.query(\"You are a helpful assistant.\", input_text).strip().lower()\n",
    "            print(f\"Response for paper '{paper}': {response}\")\n",
    "            return paper if response == \"yes\" else None\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing paper '{paper}': {e}\")\n",
    "            return None\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for topic, papers in evaluation_papers.items():\n",
    "            futures = {executor.submit(process_paper, topic, paper): paper for paper in papers}\n",
    "            pruned_papers[topic] = [future.result() for future in futures if future.result()]\n",
    "\n",
    "    return pruned_papers\n",
    "\n",
    "# Apply pruning to the selected papers\n",
    "pruned_selected_papers = prune_papers(specialized_concepts, selected_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Reinforcement Learning': ['Reinforcement Learning: An Introduction',\n",
      "                            'Asynchronous Methods for Deep Reinforcement '\n",
      "                            'Learning',\n",
      "                            'Playing Atari with Deep Reinforcement Learning',\n",
      "                            'Human-level Control through Deep Reinforcement '\n",
      "                            'Learning',\n",
      "                            'Deep Reinforcement Learning with Double '\n",
      "                            'Q-learning',\n",
      "                            'Algorithms for Reinforcement Learning',\n",
      "                            'Human-level control through deep reinforcement '\n",
      "                            'learning',\n",
      "                            'Proximal Policy Optimization Algorithms',\n",
      "                            'Model-Based Reinforcement Learning: A Survey',\n",
      "                            'Efficient Exploration in Reinforcement Learning'],\n",
      " 'Robotics': ['Principles of Robot Motion: Theory, Algorithms, and '\n",
      "              'Implementations',\n",
      "              'Learning for Robot Manipulation',\n",
      "              'Robot Manipulation: Mathematics, Algorithms, and Applications',\n",
      "              'Robotic Grasping and Fine Manipulation',\n",
      "              'Deep Learning for Robot Learning from Demonstration',\n",
      "              'Robot Learning from Demonstration']}\n",
      "\n",
      "Pruned Selected Papers for Evaluation:\n",
      "\n",
      "Topic: Reinforcement Learning\n",
      "- Reinforcement Learning: An Introduction\n",
      "- Asynchronous Methods for Deep Reinforcement Learning\n",
      "- Playing Atari with Deep Reinforcement Learning\n",
      "- Human-level Control through Deep Reinforcement Learning\n",
      "- Deep Reinforcement Learning with Double Q-learning\n",
      "- Algorithms for Reinforcement Learning\n",
      "- Human-level control through deep reinforcement learning\n",
      "- Proximal Policy Optimization Algorithms\n",
      "- Model-Based Reinforcement Learning: A Survey\n",
      "- Efficient Exploration in Reinforcement Learning\n",
      "\n",
      "Topic: Robotics\n",
      "- Principles of Robot Motion: Theory, Algorithms, and Implementations\n",
      "- Learning for Robot Manipulation\n",
      "- Robot Manipulation: Mathematics, Algorithms, and Applications\n",
      "- Robotic Grasping and Fine Manipulation\n",
      "- Deep Learning for Robot Learning from Demonstration\n",
      "- Robot Learning from Demonstration\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(pruned_selected_papers)\n",
    "\n",
    "# Output the pruned selected papers\n",
    "print(\"\\nPruned Selected Papers for Evaluation:\")\n",
    "for topic, papers in pruned_selected_papers.items():\n",
    "    print(f\"\\nTopic: {topic}\")\n",
    "    for paper in papers:\n",
    "        print(f\"- {paper}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for foundational topics for paper 'Reinforcement Learning: An Introduction': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Dynamic Programming\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Asynchronous Methods for Deep Reinforcement Learning': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization Methods\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Stochastic Processes\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Neural Networks\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Human-level control through deep reinforcement learning': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Neuroscience\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability Theory\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Deep Reinforcement Learning with Double Q-learning': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability Theory\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Algorithms for Reinforcement Learning': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Dynamic Programming\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Stochastic Processes\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Learning for Robot Manipulation': {\n",
      "    \"foundational_topics\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probabilistic Models\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Dynamical Systems\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for foundational topics for paper 'Playing Atari with Deep Reinforcement Learning': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Neuroscience\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Principles of Robot Motion: Theory, Algorithms, and Implementations': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability and Statistics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Dynamical Systems\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Numerical Methods\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Efficient Exploration in Reinforcement Learning': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Dynamic Programming\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Human-level Control through Deep Reinforcement Learning': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Neuroscience\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Computer Vision\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Proximal Policy Optimization Algorithms': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Stochastic Processes\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Model-Based Reinforcement Learning: A Survey': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probabilistic Models\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Dynamical Systems\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Robotic Grasping and Fine Manipulation':Response for foundational topics for paper 'Deep Learning for Robot Learning from Demonstration': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probabilistic Models\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      " {\n",
      "    \"foundational_topics\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Sensor Fusion\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Dynamics\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for foundational topics for paper 'Robot Learning from Demonstration': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probabilistic Models\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Robot Manipulation: Mathematics, Algorithms, and Applications': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability and Statistics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Signal Processing\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Dynamical Systems\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for resources for paper 'Efficient Exploration in Reinforcement Learning': {\n",
      "    \"Efficient Exploration in Reinforcement Learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"A First Course in Probability by Sheldon Ross\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Dynamic Programming\",\n",
      "            \"resource\": \"Dynamic Programming and Optimal Control by Dimitri P. Bertsekas\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Reinforcement Learning: An Introduction': {\n",
      "    \"Reinforcement Learning: An Introduction\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"A First Course in Probability by Sheldon Ross\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Dynamic Programming\",\n",
      "            \"resource\": \"Dynamic Programming and Optimal Control by Dimitri P. Bertsekas\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Human-level control through deep reinforcement learning': {\n",
      "    \"Human-level control through deep reinforcement learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Neuroscience\",\n",
      "            \"resource\": \"Principles of Neural Science by Eric R. Kandel, James H. Schwartz, and Thomas M. Jessell\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Theory\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"Probability and Statistics by Morris H. DeGroot and Mark J. Schervish\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Playing Atari with Deep Reinforcement Learning': {\n",
      "    \"Playing Atari with Deep Reinforcement Learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Theory\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"Probability and Statistics by Morris H. DeGroot and Mark J. Schervish\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Neuroscience\",\n",
      "            \"resource\": \"Principles of Neural Science by Eric R. Kandel, James H. Schwartz, and Thomas M. Jessell\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Asynchronous Methods for Deep Reinforcement Learning': {\n",
      "    \"Asynchronous Methods for Deep Reinforcement Learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Methods\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Stochastic Processes\",\n",
      "            \"resource\": \"Introduction to Stochastic Processes by Gregory F. Lawler\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Neural Networks\",\n",
      "            \"resource\": \"Neural Networks and Learning Machines by Simon Haykin\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Deep Reinforcement Learning with Double Q-learning': {\n",
      "    \"Deep Reinforcement Learning with Double Q-learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Theory\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"Probability and Statistics by Morris H. DeGroot and Mark J. Schervish\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Learning for Robot Manipulation': {\n",
      "    \"Learning for Robot Manipulation\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probabilistic Models\",\n",
      "            \"resource\": \"Probabilistic Graphical Models: Principles and Techniques by Daphne Koller and Nir Friedman\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Dynamical Systems\",\n",
      "            \"resource\": \"Nonlinear Dynamics and Chaos by Steven H. Strogatz\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Model-Based Reinforcement Learning: A Survey': {\n",
      "    \"Model-Based Reinforcement Learning: A Survey\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Theory\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probabilistic Models\",\n",
      "            \"resource\": \"Probabilistic Graphical Models: Principles and Techniques by Daphne Koller and Nir Friedman\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Dynamical Systems\",\n",
      "            \"resource\": \"Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry, and Engineering by Steven H. Strogatz\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Algorithms for Reinforcement Learning': {\n",
      "    \"Algorithms for Reinforcement Learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"A First Course in Probability by Sheldon Ross\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Dynamic Programming\",\n",
      "            \"resource\": \"Dynamic Programming and Optimal Control by Dimitri P. Bertsekas\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Stochastic Processes\",\n",
      "            \"resource\": \"Introduction to Stochastic Processes by Gregory F. Lawler\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Principles of Robot Motion: Theory, Algorithms, and Implementations': {\n",
      "    \"Principles of Robot Motion: Theory, Algorithms, and Implementations\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability and Statistics\",\n",
      "            \"resource\": \"Probability and Statistics for Engineers and Scientists by Ronald E. Walpole, Raymond H. Myers, Sharon L. Myers, and Keying E. Ye\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Dynamical Systems\",\n",
      "            \"resource\": \"Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry, and Engineering by Steven H. Strogatz\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Numerical Methods\",\n",
      "            \"resource\": \"Numerical Recipes: The Art of Scientific Computing by William H. Press, Saul A. Teukolsky, William T. Vetterling, and Brian P. Flannery\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Proximal Policy Optimization Algorithms': {\n",
      "    \"Proximal Policy Optimization Algorithms\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Theory\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"A First Course in Probability by Sheldon Ross\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Stochastic Processes\",\n",
      "            \"resource\": \"Introduction to Stochastic Processes by Gregory F. Lawler\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Human-level Control through Deep Reinforcement Learning': {\n",
      "    \"Human-level Control through Deep Reinforcement Learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Neuroscience\",\n",
      "            \"resource\": \"Principles of Neural Science by Eric R. Kandel, James H. Schwartz, and Thomas M. Jessell\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Theory\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"Probability and Statistics by Morris H. DeGroot and Mark J. Schervish\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Computer Vision\",\n",
      "            \"resource\": \"Computer Vision: Algorithms and Applications by Richard Szeliski\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Robot Learning from Demonstration': {\n",
      "    \"Robot Learning from Demonstration\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probabilistic Models\",\n",
      "            \"resource\": \"Probabilistic Graphical Models: Principles and Techniques by Daphne Koller and Nir Friedman\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Robot Manipulation: Mathematics, Algorithms, and Applications': {\n",
      "    \"Robot Manipulation: Mathematics, Algorithms, and Applications\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability and Statistics\",\n",
      "            \"resource\": \"Probability and Statistics for Engineers and Scientists by Ronald E. Walpole, Raymond H. Myers, Sharon L. Myers, and Keying E. Ye\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Signal Processing\",\n",
      "            \"resource\": \"Signals and Systems by Alan V. Oppenheim, Alan S. Willsky, with S. Hamid Nawab\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Dynamical Systems\",\n",
      "            \"resource\": \"Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry, and Engineering by Steven H. Strogatz\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Robotic Grasping and Fine Manipulation': {\n",
      "    \"Robotic Grasping and Fine Manipulation\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Sensor Fusion\",\n",
      "            \"resource\": \"Multisensor Data Fusion: From Algorithms and Architectural Design to Applications by Hassen Fourati\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Dynamics\",\n",
      "            \"resource\": \"Dynamics of Multibody Systems by Robert E. Roberson and Richard Schwertassek\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Deep Learning for Robot Learning from Demonstration': {\n",
      "    \"Deep Learning for Robot Learning from Demonstration\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probabilistic Models\",\n",
      "            \"resource\": \"Probabilistic Graphical Models: Principles and Techniques by Daphne Koller and Nir Friedman\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "Final Foundational Topics and Recommended Resources:\n",
      "\n",
      "Paper: Reinforcement Learning: An Introduction\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Probability Theory: A First Course in Probability by Sheldon Ross\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Dynamic Programming: Dynamic Programming and Optimal Control by Dimitri P. Bertsekas\n",
      "\n",
      "Paper: Asynchronous Methods for Deep Reinforcement Learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Optimization Methods: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Stochastic Processes: Introduction to Stochastic Processes by Gregory F. Lawler\n",
      "- Neural Networks: Neural Networks and Learning Machines by Simon Haykin\n",
      "\n",
      "Paper: Playing Atari with Deep Reinforcement Learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Optimization Theory: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Probability Theory: Probability and Statistics by Morris H. DeGroot and Mark J. Schervish\n",
      "- Neuroscience: Principles of Neural Science by Eric R. Kandel, James H. Schwartz, and Thomas M. Jessell\n",
      "\n",
      "Paper: Human-level Control through Deep Reinforcement Learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Neuroscience: Principles of Neural Science by Eric R. Kandel, James H. Schwartz, and Thomas M. Jessell\n",
      "- Optimization Theory: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Probability Theory: Probability and Statistics by Morris H. DeGroot and Mark J. Schervish\n",
      "- Computer Vision: Computer Vision: Algorithms and Applications by Richard Szeliski\n",
      "\n",
      "Paper: Deep Reinforcement Learning with Double Q-learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Optimization Theory: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Probability Theory: Probability and Statistics by Morris H. DeGroot and Mark J. Schervish\n",
      "\n",
      "Paper: Algorithms for Reinforcement Learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Probability Theory: A First Course in Probability by Sheldon Ross\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Dynamic Programming: Dynamic Programming and Optimal Control by Dimitri P. Bertsekas\n",
      "- Stochastic Processes: Introduction to Stochastic Processes by Gregory F. Lawler\n",
      "\n",
      "Paper: Human-level control through deep reinforcement learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Neuroscience: Principles of Neural Science by Eric R. Kandel, James H. Schwartz, and Thomas M. Jessell\n",
      "- Optimization Theory: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Probability Theory: Probability and Statistics by Morris H. DeGroot and Mark J. Schervish\n",
      "\n",
      "Paper: Proximal Policy Optimization Algorithms\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Optimization Theory: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Probability Theory: A First Course in Probability by Sheldon Ross\n",
      "- Stochastic Processes: Introduction to Stochastic Processes by Gregory F. Lawler\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "\n",
      "Paper: Model-Based Reinforcement Learning: A Survey\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Optimization Theory: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Probabilistic Models: Probabilistic Graphical Models: Principles and Techniques by Daphne Koller and Nir Friedman\n",
      "- Dynamical Systems: Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry, and Engineering by Steven H. Strogatz\n",
      "\n",
      "Paper: Efficient Exploration in Reinforcement Learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Probability Theory: A First Course in Probability by Sheldon Ross\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Dynamic Programming: Dynamic Programming and Optimal Control by Dimitri P. Bertsekas\n",
      "\n",
      "Paper: Principles of Robot Motion: Theory, Algorithms, and Implementations\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Probability and Statistics: Probability and Statistics for Engineers and Scientists by Ronald E. Walpole, Raymond H. Myers, Sharon L. Myers, and Keying E. Ye\n",
      "- Dynamical Systems: Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry, and Engineering by Steven H. Strogatz\n",
      "- Numerical Methods: Numerical Recipes: The Art of Scientific Computing by William H. Press, Saul A. Teukolsky, William T. Vetterling, and Brian P. Flannery\n",
      "\n",
      "Paper: Learning for Robot Manipulation\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Probabilistic Models: Probabilistic Graphical Models: Principles and Techniques by Daphne Koller and Nir Friedman\n",
      "- Dynamical Systems: Nonlinear Dynamics and Chaos by Steven H. Strogatz\n",
      "\n",
      "Paper: Robot Manipulation: Mathematics, Algorithms, and Applications\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Probability and Statistics: Probability and Statistics for Engineers and Scientists by Ronald E. Walpole, Raymond H. Myers, Sharon L. Myers, and Keying E. Ye\n",
      "- Signal Processing: Signals and Systems by Alan V. Oppenheim, Alan S. Willsky, with S. Hamid Nawab\n",
      "- Dynamical Systems: Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry, and Engineering by Steven H. Strogatz\n",
      "\n",
      "Paper: Robotic Grasping and Fine Manipulation\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Sensor Fusion: Multisensor Data Fusion: From Algorithms and Architectural Design to Applications by Hassen Fourati\n",
      "- Dynamics: Dynamics of Multibody Systems by Robert E. Roberson and Richard Schwertassek\n",
      "\n",
      "Paper: Deep Learning for Robot Learning from Demonstration\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Probabilistic Models: Probabilistic Graphical Models: Principles and Techniques by Daphne Koller and Nir Friedman\n",
      "\n",
      "Paper: Robot Learning from Demonstration\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Probabilistic Models: Probabilistic Graphical Models: Principles and Techniques by Daphne Koller and Nir Friedman\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "def find_foundational_topics_and_resources(\n",
    "    pruned_papers, existing_fundamental_concepts\n",
    "):\n",
    "    \"\"\"\n",
    "    Use an LLM agent to identify foundational topics required for the pruned list of papers\n",
    "    and recommend resources for each topic in two passes.\n",
    "    \"\"\"\n",
    "    foundational_topics = {}\n",
    "\n",
    "    def process_paper_for_topics(paper):\n",
    "        input_text = f\"\"\"\n",
    "        The project involves the following paper: {paper}.\n",
    "            Identify all foundational topics required to understand this paper.\n",
    "            Include both the existing foundational topics: {', '.join(existing_fundamental_concepts)}\n",
    "            and any additional foundational topics not listed. \n",
    "            Foundational concepts are foundational to the core concepts ({', '.join(core_concepts)}) and provide the necessary theoretical or technical background \n",
    "            to understand and work with the core concepts. Foundational topics should not include core concepts.\n",
    "            They are more advanced than prerequisites but not as specific as core concepts. \n",
    "            Examples: Machine Learning, Deep Learning, Robotic Kinematics, Control Theory.\n",
    "            Foundational topics should not be too basic either.\n",
    "            Too basic: Linear Algebra, Calculus, Classical Mechanics.\n",
    "            Respond in the following JSON format.\n",
    "            Do NOT include tick marks or any other formatting. Just ONLY provide the JSON object:\n",
    "            {{\n",
    "                \"foundational_topics\": [\n",
    "                    {{\n",
    "                        \"topic\": \"<topic>\"\n",
    "                    }},\n",
    "                    {{\n",
    "                        \"topic\": \"<topic>\"\n",
    "                    }}\n",
    "                ]\n",
    "            }}\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = gpt_agent.query(\"You are a helpful assistant.\", input_text)\n",
    "            print(f\"Response for foundational topics for paper '{paper}':\", response)\n",
    "            response_data = json.loads(response)\n",
    "            return paper, response_data.get(\"foundational_topics\", [])\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating foundational topics for paper '{paper}': {e}\")\n",
    "            return paper, []\n",
    "\n",
    "    def process_paper_for_resources(paper, topics):\n",
    "        input_text = f\"\"\"\n",
    "        The following foundational topics have been identified for the paper '{paper}': {', '.join([t['topic'] for t in topics])}.\n",
    "        For each topic, recommend a research paper, textbook, or resource that provides\n",
    "        a comprehensive introduction to the topic. Respond in the following JSON format\n",
    "        Do NOT include tick marks or any other formatting. Just ONLY provide the JSON object:\n",
    "        {{\n",
    "            \"{paper}\": [\n",
    "                {{\n",
    "                    \"topic\": \"<topic>\",\n",
    "                    \"resource\": \"<resource title and author or link>\"\n",
    "                }},\n",
    "                {{\n",
    "                    \"topic\": \"<topic>\",\n",
    "                    \"resource\": \"<resource title and author or link>\"\n",
    "                }}\n",
    "            ]\n",
    "        }}\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = gpt_agent.query(\"You are a helpful assistant.\", input_text)\n",
    "            print(f\"Response for resources for paper '{paper}':\", response)\n",
    "            response_data = json.loads(response)\n",
    "            return paper, response_data.get(paper, [])\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating resources for paper '{paper}': {e}\")\n",
    "            return paper, []\n",
    "\n",
    "    # First pass: Generate foundational topics grouped by paper\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        future_to_paper = {\n",
    "            executor.submit(process_paper_for_topics, paper): paper\n",
    "            for topic, papers in pruned_papers.items()\n",
    "            for paper in papers\n",
    "        }\n",
    "        for future in future_to_paper:\n",
    "            paper, topics = future.result()\n",
    "            foundational_topics[paper] = topics\n",
    "\n",
    "    # Second pass: Attach resources to each foundational topic\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        future_to_paper = {\n",
    "            executor.submit(process_paper_for_resources, paper, topics): paper\n",
    "            for paper, topics in foundational_topics.items()\n",
    "        }\n",
    "        for future in future_to_paper:\n",
    "            paper, resources = future.result()\n",
    "            foundational_topics[paper] = resources\n",
    "\n",
    "    return foundational_topics\n",
    "\n",
    "\n",
    "# Apply the agent to find foundational topics and resources\n",
    "final_foundational_topics = find_foundational_topics_and_resources(\n",
    "    pruned_selected_papers, fundamental_concepts\n",
    ")\n",
    "\n",
    "# Output the final foundational topics and their resources\n",
    "print(\"\\nFinal Foundational Topics and Recommended Resources:\")\n",
    "for paper, topics in final_foundational_topics.items():\n",
    "    print(f\"\\nPaper: {paper}\")\n",
    "    for topic in topics:\n",
    "        print(f\"- {topic['topic']}: {topic.get('resource', 'No resource available')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "tree_graph.html\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import utils\n",
    "\n",
    "import importlib\n",
    "importlib.reload(utils.visualization)\n",
    "from utils.tree_builder import build_tree_graph\n",
    "from utils.visualization import visualize\n",
    "\n",
    "\n",
    "# project_title = \"Title of the Project\"\n",
    "# core_concepts = [\"Reinforcement Learning\"]\n",
    "# pruned_selected_papers = {\n",
    "#     \"Reinforcement Learning\": [\n",
    "#         \"Reinforcement Learning: An Introduction\",\n",
    "#         \"Human-level control through deep reinforcement learning\",\n",
    "#     ]\n",
    "# }\n",
    "# foundational_topics = {\n",
    "#     \"Reinforcement Learning: An Introduction\": [\n",
    "#         {\n",
    "#             \"topic\": \"Machine Learning Basics\",\n",
    "#             \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\",\n",
    "#         },\n",
    "#         {\n",
    "#             \"topic\": \"Neural Networks\",\n",
    "#             \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\",\n",
    "#         },\n",
    "#     ],\n",
    "#     \"Human-level control through deep reinforcement learning\": [\n",
    "#         {\n",
    "#             \"topic\": \"Machine Learning Basics\",\n",
    "#             \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\",\n",
    "#         }\n",
    "#     ],\n",
    "# }\n",
    "\n",
    "G = build_tree_graph(\n",
    "    project_title,\n",
    "    core_concepts,\n",
    "    pruned_selected_papers,\n",
    "    final_foundational_topics,\n",
    ")\n",
    "\n",
    "# Visualize with pyvis\n",
    "visualize(G)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
