{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from agents.general_agent import Agent\n",
    "from agents.seminal_eval_agent import SeminalEvalAgent\n",
    "from agents.concept_extraction_agent import ConceptExtractionAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts and Metadata:\n",
      " {\n",
      "    \"project_title\": \"Robotic Manipulation in Unstructured Environments\",\n",
      "    \"project_summary\": \"This project involves developing a robotic system that learns to manipulate objects in unstructured environments using reinforcement learning. The system aims to generalize manipulation skills to novel objects and situations by processing visual input, planning grasping strategies, and executing tasks.\",\n",
      "    \"prerequisites\": [\"Basic programming skills\", \"Familiarity with Python\"],\n",
      "    \"fundamental_concepts\": [\"Machine Learning\", \"Robotic Kinematics\", \"Control Theory\"],\n",
      "    \"core_concepts\": [\"Reinforcement Learning\", \"Robotics\"],\n",
      "    \"specialized_concepts\": [\"RL for Grasping Strategies\", \"Visual Input Processing\", \"Pick-and-Place Tasks\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "queries_folder = os.path.join(notebook_dir, \"..\", \"queries\")\n",
    "\n",
    "gpt_agent = Agent(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "concept_agent = ConceptExtractionAgent(gpt_agent, queries_folder=queries_folder)\n",
    "\n",
    "try:\n",
    "    response = concept_agent.extract_concepts(\"robotics_grasp.json\")\n",
    "    project_title = response[\"project_title\"]\n",
    "    project_summary = response[\"project_summary\"]\n",
    "    \n",
    "    core_concepts = response[\"core_concepts\"]\n",
    "    specialized_concepts = response[\"specialized_concepts\"]\n",
    "    fundamental_concepts = response[\"fundamental_concepts\"]\n",
    "    prerequisites = response[\"prerequisites\"]\n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey papers for Robotics:\n",
      "{\n",
      "    \"papers\": [\n",
      "        {\n",
      "            \"title\": \"A Survey of Robotics and Automation for the Food Industry\",\n",
      "            \"doi\": \"10.1016/j.jfoodeng.2012.01.011\",\n",
      "            \"url\": \"https://www.sciencedirect.com/science/article/pii/S0260877412000123\",\n",
      "            \"abstract\": \"This paper reviews the state of the art in robotics and automation in the food industry, highlighting the challenges and opportunities for future research.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey of Robot Learning from Demonstration\",\n",
      "            \"doi\": \"10.1016/j.robot.2012.06.001\",\n",
      "            \"url\": \"https://www.sciencedirect.com/science/article/pii/S0921889012000772\",\n",
      "            \"abstract\": \"This survey provides an overview of the field of robot learning from demonstration, discussing various approaches and their applications.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey of Mobile Robot Localization\",\n",
      "            \"doi\": \"10.1016/j.robot.2006.03.001\",\n",
      "            \"url\": \"https://www.sciencedirect.com/science/article/pii/S0921889006000377\",\n",
      "            \"abstract\": \"This paper surveys the techniques used for mobile robot localization, focusing on probabilistic methods and their effectiveness in different environments.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey of Robot Programming Systems\",\n",
      "            \"doi\": \"10.1016/j.robot.2008.07.002\",\n",
      "            \"url\": \"https://www.sciencedirect.com/science/article/pii/S0921889008001123\",\n",
      "            \"abstract\": \"This survey reviews various robot programming systems, analyzing their features, capabilities, and suitability for different applications.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey of Robot Manipulation\",\n",
      "            \"doi\": \"10.1016/j.robot.2010.06.001\",\n",
      "            \"url\": \"https://www.sciencedirect.com/science/article/pii/S0921889010000772\",\n",
      "            \"abstract\": \"This paper provides a comprehensive survey of robot manipulation, covering the key techniques and challenges in the field.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey of Multi-Robot Systems\",\n",
      "            \"doi\": \"10.1016/j.robot.2005.10.004\",\n",
      "            \"url\": \"https://www.sciencedirect.com/science/article/pii/S0921889005001123\",\n",
      "            \"abstract\": \"This survey explores the area of multi-robot systems, discussing coordination, communication, and control strategies.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Survey papers for Reinforcement Learning:\n",
      "{\n",
      "    \"papers\": [\n",
      "        {\n",
      "            \"title\": \"A Survey on Reinforcement Learning: Open Problems and Applications\",\n",
      "            \"doi\": \"10.1109/ACCESS.2020.2992344\",\n",
      "            \"url\": \"https://ieeexplore.ieee.org/document/9096828\",\n",
      "            \"abstract\": \"This paper provides a comprehensive survey of reinforcement learning, discussing open problems and various applications in different domains.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Deep Reinforcement Learning: A Survey\",\n",
      "            \"doi\": \"10.1145/3386252\",\n",
      "            \"url\": \"https://dl.acm.org/doi/10.1145/3386252\",\n",
      "            \"abstract\": \"This survey reviews the recent advances in deep reinforcement learning, highlighting key algorithms and their applications.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey of Reinforcement Learning Algorithms for Dynamically Varying Environments\",\n",
      "            \"doi\": \"10.1016/j.artint.2020.103500\",\n",
      "            \"url\": \"https://www.sciencedirect.com/science/article/pii/S0004370220301530\",\n",
      "            \"abstract\": \"The paper surveys reinforcement learning algorithms designed for environments that change over time, discussing their strengths and weaknesses.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Reinforcement Learning: A Survey\",\n",
      "            \"doi\": \"10.1145/3315454\",\n",
      "            \"url\": \"https://dl.acm.org/doi/10.1145/3315454\",\n",
      "            \"abstract\": \"This survey provides an overview of reinforcement learning, covering foundational concepts, key algorithms, and future research directions.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey on Multi-Agent Reinforcement Learning: From Foundations to Applications\",\n",
      "            \"doi\": \"10.1109/TCYB.2020.3045894\",\n",
      "            \"url\": \"https://ieeexplore.ieee.org/document/9318945\",\n",
      "            \"abstract\": \"This paper surveys multi-agent reinforcement learning, discussing foundational theories and a wide range of applications.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey on Model-Based Reinforcement Learning\",\n",
      "            \"doi\": \"10.1016/j.artint.2020.103500\",\n",
      "            \"url\": \"https://www.sciencedirect.com/science/article/pii/S0004370220301530\",\n",
      "            \"abstract\": \"The survey reviews model-based reinforcement learning approaches, highlighting their advantages and challenges compared to model-free methods.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "Survey Papers:\n",
      "\n",
      "Concept: Reinforcement Learning\n",
      "- A Survey on Reinforcement Learning: Open Problems and Applications\n",
      "- Deep Reinforcement Learning: A Survey\n",
      "- A Survey of Reinforcement Learning Algorithms for Dynamically Varying Environments\n",
      "- Reinforcement Learning: A Survey\n",
      "- A Survey on Multi-Agent Reinforcement Learning: From Foundations to Applications\n",
      "- A Survey on Model-Based Reinforcement Learning\n",
      "\n",
      "Concept: Robotics\n",
      "- A Survey of Robotics and Automation for the Food Industry\n",
      "- A Survey of Robot Learning from Demonstration\n",
      "- A Survey of Mobile Robot Localization\n",
      "- A Survey of Robot Programming Systems\n",
      "- A Survey of Robot Manipulation\n",
      "- A Survey of Multi-Robot Systems\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Query for survey papers for each core concept\n",
    "survey_papers = {}\n",
    "\n",
    "def find_survey_papers(concept):\n",
    "    \"\"\"\n",
    "    Query the agent for seminal papers for a given concept.\n",
    "    \"\"\"\n",
    "    input_text = f\"\"\"\n",
    "    Provide 6 survey papers on the topic '{concept}' along with their DOI id's, URLs, and other metadata in the following JSON format.\n",
    "    Do NOT include tick marks or any other formatting. Just ONLY provide the JSON object: \n",
    "    {{\n",
    "        \"papers\": [\n",
    "            {{\n",
    "                \"title\": \"<title>\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        gpt_response = gpt_agent.query(\"You are a helpful assistant.\", input_text)\n",
    "        print(f\"Survey papers for {concept}:\\n{json.dumps(json.loads(gpt_response), indent=4)}\")\n",
    "        return concept, json.loads(gpt_response)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Failed to parse GPT-4 response for {concept}. Response: {gpt_response}\")\n",
    "        return concept, []\n",
    "\n",
    "# Parallelize the process of querying for survey papers\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future_to_concept = {executor.submit(find_survey_papers, concept): concept for concept in core_concepts}\n",
    "    for future in future_to_concept:\n",
    "        concept, papers = future.result()\n",
    "        survey_papers[concept] = papers\n",
    "\n",
    "# Output the survey papers\n",
    "print(\"\\nSurvey Papers:\")\n",
    "for concept, papers in survey_papers.items():\n",
    "    print(f\"\\nConcept: {concept}\")\n",
    "    for paper in papers.get(\"papers\", []):\n",
    "        print(f\"- {paper['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seminal Paper Counts by Topic:\n",
      "\n",
      "Concept: Reinforcement Learning\n",
      "Reinforcement Learning: An Introduction: 6\n",
      "Asynchronous Methods for Deep Reinforcement Learning: 2\n",
      "Playing Atari with Deep Reinforcement Learning: 2\n",
      "Human-level Control through Deep Reinforcement Learning: 2\n",
      "Deep Reinforcement Learning with Double Q-learning: 2\n",
      "Algorithms for Reinforcement Learning: 2\n",
      "Human-level control through deep reinforcement learning: 1\n",
      "Proximal Policy Optimization Algorithms: 1\n",
      "A Survey of Reinforcement Learning Algorithms: 1\n",
      "Dynamic Programming and Optimal Control: 1\n",
      "Deep Reinforcement Learning with Dynamic Environments: 1\n",
      "Adaptive Reinforcement Learning in Non-Stationary Environments: 1\n",
      "Temporal Difference Learning and TD-Gammon: 1\n",
      "Policy Gradient Methods for Reinforcement Learning with Function Approximation: 1\n",
      "Multi-Agent Systems: Algorithmic, Game-Theoretic, and Logical Foundations: 1\n",
      "Cooperative Multi-Agent Reinforcement Learning: A Survey: 1\n",
      "Model-Based Reinforcement Learning: A Survey: 1\n",
      "Dyna: An Integrated Architecture for Learning, Planning, and Reacting: 1\n",
      "Efficient Exploration in Reinforcement Learning: 1\n",
      "AlphaGo Zero: Mastering the Game of Go without Human Knowledge: 1\n",
      "\n",
      "Concept: Robotics\n",
      "Principles of Robot Motion: Theory, Algorithms, and Implementations: 3\n",
      "Robotics in Food Processing: An Overview: 1\n",
      "Automation Technologies for the Food Industry: 1\n",
      "Advances in Food Robotics: 1\n",
      "Innovations in Food Manufacturing Automation: 1\n",
      "The Role of Robotics in Modern Food Production: 1\n",
      "Programming by Demonstration: A Method for Robot Programming: 1\n",
      "Learning from Demonstration: 1\n",
      "Robot Learning from Demonstration: 1\n",
      "Imitation Learning: A Survey of Learning Methods: 1\n",
      "Deep Learning for Robot Learning from Demonstration: 1\n",
      "Probabilistic Robotics: 1\n",
      "Mobile Robot Localization Using Particle Filters: 1\n",
      "Monte Carlo Localization: Efficient Position Estimation for Mobile Robots: 1\n",
      "A Survey of Simultaneous Localization and Mapping (SLAM) Algorithms: 1\n",
      "Introduction to Autonomous Mobile Robots: 1\n",
      "Introduction to Robotics: Mechanics and Control: 1\n",
      "Robot Programming: A Practical Guide to Behavior-Based Robotics: 1\n",
      "Programming Robots with ROS: 1\n",
      "Robot Operating System (ROS): The Complete Reference: 1\n",
      "Robot Manipulation: Mathematics, Algorithms, and Applications: 1\n",
      "Modern Robotics: Mechanics, Planning, and Control: 1\n",
      "Robotic Grasping and Fine Manipulation: 1\n",
      "Learning for Robot Manipulation: 1\n",
      "Cooperative Control of Multi-Robot Systems: 1\n",
      "Distributed Algorithms for Multi-Robot Systems: 1\n",
      "Swarm Robotics: From Inspiration to Applications: 1\n",
      "Multi-Robot Systems: From Swarms to Intelligent Automata: 1\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Separate dictionaries for seminal paper counts by topic\n",
    "seminal_paper_counts_by_topic = {}\n",
    "top_references = {}\n",
    "\n",
    "def find_seminal_works(concept, paper):\n",
    "    \"\"\"\n",
    "    Query the agent for the 5 most seminal works for a given paper.\n",
    "    \"\"\"\n",
    "    title = paper.get(\"title\", \"Unknown Title\")\n",
    "    input_text = f\"\"\"\n",
    "    For the paper titled '{title}', provide the 5 most seminal works (including papers and textbooks) in the field that are related to this paper and would likely be cited. \n",
    "    If you cannot access external databases, respond with 5 hypothetical seminal works based on the paper title in the following example JSON format (not with this content, but with the same structure):\n",
    "    Do NOT include tick marks or any other formatting. Just ONLY provide the JSON object: \n",
    "    {{\n",
    "        \"seminal_works\": [\n",
    "            {{\"title\": \"Seminal Work 1\", \"year\": 1998}},\n",
    "            {{\"title\": \"Seminal Work 2\", \"year\": 2013}},\n",
    "            {{\"title\": \"Seminal Work 3\", \"year\": 2015}},\n",
    "            {{\"title\": \"Seminal Work 4\", \"year\": 2020}},\n",
    "            {{\"title\": \"Seminal Work 5\", \"year\": 2021}}\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        gpt_response = gpt_agent.query(\"You are a helpful assistant.\", input_text)\n",
    "        references = json.loads(gpt_response).get(\"seminal_works\", [])\n",
    "        return concept, title, references\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Failed to parse GPT-4 response for paper: {title}\")\n",
    "        return concept, title, []\n",
    "\n",
    "# Parallelize the process of querying for seminal works\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future_to_paper = {\n",
    "        executor.submit(find_seminal_works, concept, paper): (concept, paper)\n",
    "        for concept, papers in survey_papers.items()\n",
    "        for paper in papers.get(\"papers\", [])\n",
    "    }\n",
    "    for future in future_to_paper:\n",
    "        concept, title, references = future.result()\n",
    "        if concept not in top_references:\n",
    "            top_references[concept] = {}\n",
    "        if concept not in seminal_paper_counts_by_topic:\n",
    "            seminal_paper_counts_by_topic[concept] = {}\n",
    "\n",
    "        top_references[concept][title] = references\n",
    "        for ref in references:\n",
    "            ref_title = ref[\"title\"]\n",
    "            if ref_title in seminal_paper_counts_by_topic[concept]:\n",
    "                seminal_paper_counts_by_topic[concept][ref_title] += 1\n",
    "            else:\n",
    "                seminal_paper_counts_by_topic[concept][ref_title] = 1\n",
    "\n",
    "# Output the seminal paper counts for each topic\n",
    "print(\"\\nSeminal Paper Counts by Topic:\")\n",
    "for concept, counts in seminal_paper_counts_by_topic.items():\n",
    "    print(f\"\\nConcept: {concept}\")\n",
    "    sorted_counts = sorted(counts.items(), key=lambda item: item[1], reverse=True)\n",
    "    for paper_title, count in sorted_counts:\n",
    "        print(f\"{paper_title}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 'Reinforcement Learning': High-count papers selected: ['Reinforcement Learning: An Introduction', 'Asynchronous Methods for Deep Reinforcement Learning', 'Playing Atari with Deep Reinforcement Learning', 'Human-level Control through Deep Reinforcement Learning', 'Deep Reinforcement Learning with Double Q-learning', 'Algorithms for Reinforcement Learning']\n",
      "Topic 'Reinforcement Learning': Final selected papers: ['Reinforcement Learning: An Introduction', 'Asynchronous Methods for Deep Reinforcement Learning', 'Playing Atari with Deep Reinforcement Learning', 'Human-level Control through Deep Reinforcement Learning', 'Deep Reinforcement Learning with Double Q-learning', 'Algorithms for Reinforcement Learning', 'Human-level control through deep reinforcement learning', 'Proximal Policy Optimization Algorithms', 'Deep Reinforcement Learning with Dynamic Environments', 'Adaptive Reinforcement Learning in Non-Stationary Environments', 'Model-Based Reinforcement Learning: A Survey', 'Efficient Exploration in Reinforcement Learning']\n",
      "Topic 'Robotics': High-count papers selected: ['Principles of Robot Motion: Theory, Algorithms, and Implementations']\n",
      "Topic 'Reinforcement Learning': Final selected papers: ['Reinforcement Learning: An Introduction', 'Asynchronous Methods for Deep Reinforcement Learning', 'Playing Atari with Deep Reinforcement Learning', 'Human-level Control through Deep Reinforcement Learning', 'Deep Reinforcement Learning with Double Q-learning', 'Algorithms for Reinforcement Learning', 'Human-level control through deep reinforcement learning', 'Proximal Policy Optimization Algorithms', 'Deep Reinforcement Learning with Dynamic Environments', 'Adaptive Reinforcement Learning in Non-Stationary Environments', 'Model-Based Reinforcement Learning: A Survey', 'Efficient Exploration in Reinforcement Learning']\n",
      "Topic 'Robotics': High-count papers selected: ['Principles of Robot Motion: Theory, Algorithms, and Implementations']\n",
      "Topic 'Robotics': Final selected papers: ['Principles of Robot Motion: Theory, Algorithms, and Implementations', 'Learning for Robot Manipulation', 'Robot Manipulation: Mathematics, Algorithms, and Applications', 'Robotic Grasping and Fine Manipulation', 'Deep Learning for Robot Learning from Demonstration', 'Robot Learning from Demonstration', 'Imitation Learning: A Survey of Learning Methods']\n",
      "\n",
      "Selected Papers for Evaluation:\n",
      "\n",
      "Topic: Reinforcement Learning\n",
      "- Reinforcement Learning: An Introduction\n",
      "- Asynchronous Methods for Deep Reinforcement Learning\n",
      "- Playing Atari with Deep Reinforcement Learning\n",
      "- Human-level Control through Deep Reinforcement Learning\n",
      "- Deep Reinforcement Learning with Double Q-learning\n",
      "- Algorithms for Reinforcement Learning\n",
      "- Human-level control through deep reinforcement learning\n",
      "- Proximal Policy Optimization Algorithms\n",
      "- Deep Reinforcement Learning with Dynamic Environments\n",
      "- Adaptive Reinforcement Learning in Non-Stationary Environments\n",
      "- Model-Based Reinforcement Learning: A Survey\n",
      "- Efficient Exploration in Reinforcement Learning\n",
      "\n",
      "Topic: Robotics\n",
      "- Principles of Robot Motion: Theory, Algorithms, and Implementations\n",
      "- Learning for Robot Manipulation\n",
      "- Robot Manipulation: Mathematics, Algorithms, and Applications\n",
      "- Robotic Grasping and Fine Manipulation\n",
      "- Deep Learning for Robot Learning from Demonstration\n",
      "- Robot Learning from Demonstration\n",
      "- Imitation Learning: A Survey of Learning Methods\n",
      "Topic 'Robotics': Final selected papers: ['Principles of Robot Motion: Theory, Algorithms, and Implementations', 'Learning for Robot Manipulation', 'Robot Manipulation: Mathematics, Algorithms, and Applications', 'Robotic Grasping and Fine Manipulation', 'Deep Learning for Robot Learning from Demonstration', 'Robot Learning from Demonstration', 'Imitation Learning: A Survey of Learning Methods']\n",
      "\n",
      "Selected Papers for Evaluation:\n",
      "\n",
      "Topic: Reinforcement Learning\n",
      "- Reinforcement Learning: An Introduction\n",
      "- Asynchronous Methods for Deep Reinforcement Learning\n",
      "- Playing Atari with Deep Reinforcement Learning\n",
      "- Human-level Control through Deep Reinforcement Learning\n",
      "- Deep Reinforcement Learning with Double Q-learning\n",
      "- Algorithms for Reinforcement Learning\n",
      "- Human-level control through deep reinforcement learning\n",
      "- Proximal Policy Optimization Algorithms\n",
      "- Deep Reinforcement Learning with Dynamic Environments\n",
      "- Adaptive Reinforcement Learning in Non-Stationary Environments\n",
      "- Model-Based Reinforcement Learning: A Survey\n",
      "- Efficient Exploration in Reinforcement Learning\n",
      "\n",
      "Topic: Robotics\n",
      "- Principles of Robot Motion: Theory, Algorithms, and Implementations\n",
      "- Learning for Robot Manipulation\n",
      "- Robot Manipulation: Mathematics, Algorithms, and Applications\n",
      "- Robotic Grasping and Fine Manipulation\n",
      "- Deep Learning for Robot Learning from Demonstration\n",
      "- Robot Learning from Demonstration\n",
      "- Imitation Learning: A Survey of Learning Methods\n"
     ]
    }
   ],
   "source": [
    "# Initialize the evaluation agent\n",
    "seminal_eval_agent = SeminalEvalAgent(seminal_paper_counts_by_topic, gpt_agent, project_summary)\n",
    "\n",
    "# Select papers based on the criteria\n",
    "selected_papers = seminal_eval_agent.select_papers()\n",
    "\n",
    "# Output the selected papers for evaluation\n",
    "print(\"\\nSelected Papers for Evaluation:\")\n",
    "for topic, papers in selected_papers.items():\n",
    "    print(f\"\\nTopic: {topic}\")\n",
    "    for paper in papers:\n",
    "        print(f\"- {paper}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for paper 'Asynchronous Methods for Deep Reinforcement Learning': yes\n",
      "Response for paper 'Reinforcement Learning: An Introduction': yes\n",
      "Response for paper 'Proximal Policy Optimization Algorithms': yes\n",
      "Response for paper 'Model-Based Reinforcement Learning: A Survey': yes\n",
      "Response for paper 'Deep Reinforcement Learning with Dynamic Environments': no\n",
      "Response for paper 'Deep Reinforcement Learning with Double Q-learning': yes\n",
      "Response for paper 'Efficient Exploration in Reinforcement Learning': yes\n",
      "Response for paper 'Adaptive Reinforcement Learning in Non-Stationary Environments': no\n",
      "Response for paper 'Deep Reinforcement Learning with Dynamic Environments': no\n",
      "Response for paper 'Deep Reinforcement Learning with Double Q-learning': yes\n",
      "Response for paper 'Efficient Exploration in Reinforcement Learning': yes\n",
      "Response for paper 'Adaptive Reinforcement Learning in Non-Stationary Environments': no\n",
      "Response for paper 'Human-level Control through Deep Reinforcement Learning': yes\n",
      "Response for paper 'Algorithms for Reinforcement Learning': yes\n",
      "Response for paper 'Human-level Control through Deep Reinforcement Learning': yes\n",
      "Response for paper 'Algorithms for Reinforcement Learning': yes\n",
      "Response for paper 'Human-level control through deep reinforcement learning': yes\n",
      "Response for paper 'Human-level control through deep reinforcement learning': yes\n",
      "Response for paper 'Playing Atari with Deep Reinforcement Learning': yes\n",
      "Response for paper 'Playing Atari with Deep Reinforcement Learning': yes\n",
      "Response for paper 'Learning for Robot Manipulation': yes\n",
      "Response for paper 'Principles of Robot Motion: Theory, Algorithms, and Implementations': yes\n",
      "Response for paper 'Robot Manipulation: Mathematics, Algorithms, and Applications': yes\n",
      "Response for paper 'Robot Learning from Demonstration': yes\n",
      "Response for paper 'Imitation Learning: A Survey of Learning Methods': no\n",
      "Response for paper 'Deep Learning for Robot Learning from Demonstration': yes\n",
      "Response for paper 'Learning for Robot Manipulation': yes\n",
      "Response for paper 'Principles of Robot Motion: Theory, Algorithms, and Implementations': yes\n",
      "Response for paper 'Robot Manipulation: Mathematics, Algorithms, and Applications': yes\n",
      "Response for paper 'Robot Learning from Demonstration': yes\n",
      "Response for paper 'Imitation Learning: A Survey of Learning Methods': no\n",
      "Response for paper 'Deep Learning for Robot Learning from Demonstration': yes\n",
      "Response for paper 'Robotic Grasping and Fine Manipulation': yes\n",
      "Response for paper 'Robotic Grasping and Fine Manipulation': yes\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Prune evaluation papers using specialized topics\n",
    "def prune_papers(specialized_topics, evaluation_papers):\n",
    "    \"\"\"\n",
    "    Use an LLM agent to filter evaluation papers based on specialized topics.\n",
    "    \"\"\"\n",
    "    pruned_papers = {}\n",
    "\n",
    "    def process_paper(topic, paper):\n",
    "        input_text = f\"\"\"\n",
    "        The project focuses on the following specialized topics: {', '.join(specialized_topics)}.\n",
    "        Determine if the paper titled '{paper}' is directly relevant and truly essential to either one of these:\n",
    "        1. general understanding of {topic}\n",
    "        2. the project: {project_summary}.\n",
    "\n",
    "        Respond with ONLY the word \"yes\" (nothing other than the word) if it is relevant or beneficial to understanding the topic in general.\n",
    "        Otherwise respond with ONLY the word \"no\" (nothing other than the word).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = gpt_agent.query(\"You are a helpful assistant.\", input_text).strip().lower()\n",
    "            print(f\"Response for paper '{paper}': {response}\")\n",
    "            return paper if response == \"yes\" else None\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing paper '{paper}': {e}\")\n",
    "            return None\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for topic, papers in evaluation_papers.items():\n",
    "            futures = {executor.submit(process_paper, topic, paper): paper for paper in papers}\n",
    "            pruned_papers[topic] = [future.result() for future in futures if future.result()]\n",
    "\n",
    "    return pruned_papers\n",
    "\n",
    "# Apply pruning to the selected papers\n",
    "pruned_selected_papers = prune_papers(specialized_concepts, selected_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Reinforcement Learning': ['Reinforcement Learning: An Introduction',\n",
      "                            'Asynchronous Methods for Deep Reinforcement '\n",
      "                            'Learning',\n",
      "                            'Playing Atari with Deep Reinforcement Learning',\n",
      "                            'Human-level Control through Deep Reinforcement '\n",
      "                            'Learning',\n",
      "                            'Deep Reinforcement Learning with Double '\n",
      "                            'Q-learning',\n",
      "                            'Algorithms for Reinforcement Learning',\n",
      "                            'Human-level control through deep reinforcement '\n",
      "                            'learning',\n",
      "                            'Proximal Policy Optimization Algorithms',\n",
      "                            'Model-Based Reinforcement Learning: A Survey',\n",
      "                            'Efficient Exploration in Reinforcement Learning'],\n",
      " 'Robotics': ['Principles of Robot Motion: Theory, Algorithms, and '\n",
      "              'Implementations',\n",
      "              'Learning for Robot Manipulation',\n",
      "              'Robot Manipulation: Mathematics, Algorithms, and Applications',\n",
      "              'Robotic Grasping and Fine Manipulation',\n",
      "              'Deep Learning for Robot Learning from Demonstration',\n",
      "              'Robot Learning from Demonstration']}\n",
      "\n",
      "Pruned Selected Papers for Evaluation:\n",
      "\n",
      "Topic: Reinforcement Learning\n",
      "- Reinforcement Learning: An Introduction\n",
      "- Asynchronous Methods for Deep Reinforcement Learning\n",
      "- Playing Atari with Deep Reinforcement Learning\n",
      "- Human-level Control through Deep Reinforcement Learning\n",
      "- Deep Reinforcement Learning with Double Q-learning\n",
      "- Algorithms for Reinforcement Learning\n",
      "- Human-level control through deep reinforcement learning\n",
      "- Proximal Policy Optimization Algorithms\n",
      "- Model-Based Reinforcement Learning: A Survey\n",
      "- Efficient Exploration in Reinforcement Learning\n",
      "\n",
      "Topic: Robotics\n",
      "- Principles of Robot Motion: Theory, Algorithms, and Implementations\n",
      "- Learning for Robot Manipulation\n",
      "- Robot Manipulation: Mathematics, Algorithms, and Applications\n",
      "- Robotic Grasping and Fine Manipulation\n",
      "- Deep Learning for Robot Learning from Demonstration\n",
      "- Robot Learning from Demonstration\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(pruned_selected_papers)\n",
    "\n",
    "# Output the pruned selected papers\n",
    "print(\"\\nPruned Selected Papers for Evaluation:\")\n",
    "for topic, papers in pruned_selected_papers.items():\n",
    "    print(f\"\\nTopic: {topic}\")\n",
    "    for paper in papers:\n",
    "        print(f\"- {paper}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for foundational topics for paper 'Proximal Policy Optimization Algorithms': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Stochastic Processes\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Human-level Control through Deep Reinforcement Learning': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Neural Networks\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization Methods\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Markov Decision Processes\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Deep Reinforcement Learning with Double Q-learning': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Reinforcement Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability Theory\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Model-Based Reinforcement Learning: A Survey': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Dynamical Systems\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probabilistic Models\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Efficient Exploration in Reinforcement Learning': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Markov Decision Processes\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Principles of Robot Motion: Theory, Algorithms, and Implementations': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Computer Vision\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Sensor Fusion\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Motion Planning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Artificial Intelligence\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Learning for Robot Manipulation': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Reinforcement Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Computer Vision\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Reinforcement Learning: An Introduction': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Dynamic Programming\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Markov Decision Processes\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Human-level control through deep reinforcement learning': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Neuroscience\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Computer Vision\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Principles of Robot Motion: Theory, Algorithms, and Implementations': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Computer Vision\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Sensor Fusion\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Motion Planning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Artificial Intelligence\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Learning for Robot Manipulation': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Reinforcement Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Computer Vision\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Reinforcement Learning: An Introduction': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Dynamic Programming\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Markov Decision Processes\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Human-level control through deep reinforcement learning': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Neuroscience\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Computer Vision\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Algorithms for Reinforcement Learning': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Dynamic Programming\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Playing Atari with Deep Reinforcement Learning': {\n",
      "    \"foundational_topics\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Reinforcement Learning\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Neural Networks\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Methods\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for foundational topics for paper 'Asynchronous Methods for Deep Reinforcement Learning': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Reinforcement Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization Methods\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Stochastic Processes\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Algorithms for Reinforcement Learning': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Probability Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Dynamic Programming\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Playing Atari with Deep Reinforcement Learning': {\n",
      "    \"foundational_topics\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Reinforcement Learning\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Neural Networks\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Methods\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for foundational topics for paper 'Asynchronous Methods for Deep Reinforcement Learning': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Reinforcement Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization Methods\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Stochastic Processes\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Robot Manipulation: Mathematics, Algorithms, and Applications': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Computer Vision\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Sensor Fusion\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Deep Learning for Robot Learning from Demonstration': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Reinforcement Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Computer Vision\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Robotic Grasping and Fine Manipulation': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Computer Vision\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Robot Manipulation: Mathematics, Algorithms, and Applications': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Computer Vision\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Sensor Fusion\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Deep Learning for Robot Learning from Demonstration': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Reinforcement Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Computer Vision\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Robotic Grasping and Fine Manipulation': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Computer Vision\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Optimization\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Robot Learning from Demonstration': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Reinforcement Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Computer Vision\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Human-Robot Interaction\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for foundational topics for paper 'Robot Learning from Demonstration': {\n",
      "  \"foundational_topics\": [\n",
      "    {\n",
      "      \"topic\": \"Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Robotic Kinematics\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Control Theory\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Reinforcement Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Computer Vision\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"Human-Robot Interaction\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response for resources for paper 'Playing Atari with Deep Reinforcement Learning': {\n",
      "    \"Playing Atari with Deep Reinforcement Learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Reinforcement Learning\",\n",
      "            \"resource\": \"Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Neural Networks\",\n",
      "            \"resource\": \"Neural Networks and Learning Machines by Simon Haykin\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Methods\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Reinforcement Learning: An Introduction': {\n",
      "    \"Reinforcement Learning: An Introduction\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"A First Course in Probability by Sheldon Ross\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Dynamic Programming\",\n",
      "            \"resource\": \"Dynamic Programming and Optimal Control by Dimitri P. Bertsekas\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Markov Decision Processes\",\n",
      "            \"resource\": \"Markov Decision Processes: Discrete Stochastic Dynamic Programming by Martin L. Puterman\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Playing Atari with Deep Reinforcement Learning': {\n",
      "    \"Playing Atari with Deep Reinforcement Learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Reinforcement Learning\",\n",
      "            \"resource\": \"Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Neural Networks\",\n",
      "            \"resource\": \"Neural Networks and Learning Machines by Simon Haykin\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Methods\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Reinforcement Learning: An Introduction': {\n",
      "    \"Reinforcement Learning: An Introduction\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"A First Course in Probability by Sheldon Ross\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Dynamic Programming\",\n",
      "            \"resource\": \"Dynamic Programming and Optimal Control by Dimitri P. Bertsekas\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Markov Decision Processes\",\n",
      "            \"resource\": \"Markov Decision Processes: Discrete Stochastic Dynamic Programming by Martin L. Puterman\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Algorithms for Reinforcement Learning': {\n",
      "    \"Algorithms for Reinforcement Learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"A First Course in Probability by Sheldon Ross\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Dynamic Programming\",\n",
      "            \"resource\": \"Dynamic Programming and Optimal Control by Dimitri P. Bertsekas\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Efficient Exploration in Reinforcement Learning': {\n",
      "    \"Efficient Exploration in Reinforcement Learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"A First Course in Probability by Sheldon Ross\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Markov Decision Processes\",\n",
      "            \"resource\": \"Markov Decision Processes: Discrete Stochastic Dynamic Programming by Martin L. Puterman\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Algorithms for Reinforcement Learning': {\n",
      "    \"Algorithms for Reinforcement Learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"A First Course in Probability by Sheldon Ross\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Dynamic Programming\",\n",
      "            \"resource\": \"Dynamic Programming and Optimal Control by Dimitri P. Bertsekas\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Efficient Exploration in Reinforcement Learning': {\n",
      "    \"Efficient Exploration in Reinforcement Learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"A First Course in Probability by Sheldon Ross\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Markov Decision Processes\",\n",
      "            \"resource\": \"Markov Decision Processes: Discrete Stochastic Dynamic Programming by Martin L. Puterman\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Deep Reinforcement Learning with Double Q-learning': {\n",
      "    \"Deep Reinforcement Learning with Double Q-learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Reinforcement Learning\",\n",
      "            \"resource\": \"Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Theory\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"Probability and Statistics by Morris H. DeGroot and Mark J. Schervish\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Principles of Robot Motion: Theory, Algorithms, and Implementations': {\n",
      "    \"Principles of Robot Motion: Theory, Algorithms, and Implementations\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Computer Vision\",\n",
      "            \"resource\": \"Computer Vision: Algorithms and Applications by Richard Szeliski\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Sensor Fusion\",\n",
      "            \"resource\": \"Multisensor Data Fusion: From Algorithms and Architectural Design to Applications by Hassen Fourati\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Motion Planning\",\n",
      "            \"resource\": \"Planning Algorithms by Steven M. LaValle\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Artificial Intelligence\",\n",
      "            \"resource\": \"Artificial Intelligence: A Modern Approach by Stuart Russell and Peter Norvig\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Human-level Control through Deep Reinforcement Learning': {\n",
      "    \"Human-level Control through Deep Reinforcement Learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Neural Networks\",\n",
      "            \"resource\": \"Neural Networks and Learning Machines by Simon Haykin\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Methods\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Markov Decision Processes\",\n",
      "            \"resource\": \"Markov Decision Processes: Discrete Stochastic Dynamic Programming by Martin L. Puterman\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Asynchronous Methods for Deep Reinforcement Learning': {\n",
      "    \"Asynchronous Methods for Deep Reinforcement Learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Reinforcement Learning\",\n",
      "            \"resource\": \"Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Methods\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Stochastic Processes\",\n",
      "            \"resource\": \"Introduction to Stochastic Processes by Gregory F. Lawler\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Deep Reinforcement Learning with Double Q-learning': {\n",
      "    \"Deep Reinforcement Learning with Double Q-learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Reinforcement Learning\",\n",
      "            \"resource\": \"Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Theory\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"Probability and Statistics by Morris H. DeGroot and Mark J. Schervish\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Principles of Robot Motion: Theory, Algorithms, and Implementations': {\n",
      "    \"Principles of Robot Motion: Theory, Algorithms, and Implementations\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Computer Vision\",\n",
      "            \"resource\": \"Computer Vision: Algorithms and Applications by Richard Szeliski\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Sensor Fusion\",\n",
      "            \"resource\": \"Multisensor Data Fusion: From Algorithms and Architectural Design to Applications by Hassen Fourati\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Motion Planning\",\n",
      "            \"resource\": \"Planning Algorithms by Steven M. LaValle\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Artificial Intelligence\",\n",
      "            \"resource\": \"Artificial Intelligence: A Modern Approach by Stuart Russell and Peter Norvig\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Human-level Control through Deep Reinforcement Learning': {\n",
      "    \"Human-level Control through Deep Reinforcement Learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Neural Networks\",\n",
      "            \"resource\": \"Neural Networks and Learning Machines by Simon Haykin\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Methods\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Markov Decision Processes\",\n",
      "            \"resource\": \"Markov Decision Processes: Discrete Stochastic Dynamic Programming by Martin L. Puterman\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Asynchronous Methods for Deep Reinforcement Learning': {\n",
      "    \"Asynchronous Methods for Deep Reinforcement Learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Reinforcement Learning\",\n",
      "            \"resource\": \"Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Methods\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Stochastic Processes\",\n",
      "            \"resource\": \"Introduction to Stochastic Processes by Gregory F. Lawler\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Learning for Robot Manipulation': {\n",
      "    \"Learning for Robot Manipulation\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Reinforcement Learning\",\n",
      "            \"resource\": \"Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Computer Vision\",\n",
      "            \"resource\": \"Computer Vision: Algorithms and Applications by Richard Szeliski\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Learning for Robot Manipulation': {\n",
      "    \"Learning for Robot Manipulation\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Reinforcement Learning\",\n",
      "            \"resource\": \"Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Computer Vision\",\n",
      "            \"resource\": \"Computer Vision: Algorithms and Applications by Richard Szeliski\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Human-level control through deep reinforcement learning': {\n",
      "    \"Human-level control through deep reinforcement learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Neuroscience\",\n",
      "            \"resource\": \"Principles of Neural Science by Eric R. Kandel, James H. Schwartz, and Thomas M. Jessell\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Theory\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"Probability and Statistics by Morris H. DeGroot and Mark J. Schervish\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Computer Vision\",\n",
      "            \"resource\": \"Computer Vision: Algorithms and Applications by Richard Szeliski\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Human-level control through deep reinforcement learning': {\n",
      "    \"Human-level control through deep reinforcement learning\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Neuroscience\",\n",
      "            \"resource\": \"Principles of Neural Science by Eric R. Kandel, James H. Schwartz, and Thomas M. Jessell\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Theory\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"Probability and Statistics by Morris H. DeGroot and Mark J. Schervish\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Computer Vision\",\n",
      "            \"resource\": \"Computer Vision: Algorithms and Applications by Richard Szeliski\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Model-Based Reinforcement Learning: A Survey': {\n",
      "    \"Model-Based Reinforcement Learning: A Survey\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Theory\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Dynamical Systems\",\n",
      "            \"resource\": \"Nonlinear Dynamics and Chaos by Steven H. Strogatz\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probabilistic Models\",\n",
      "            \"resource\": \"Probabilistic Graphical Models: Principles and Techniques by Daphne Koller and Nir Friedman\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Model-Based Reinforcement Learning: A Survey': {\n",
      "    \"Model-Based Reinforcement Learning: A Survey\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Theory\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Dynamical Systems\",\n",
      "            \"resource\": \"Nonlinear Dynamics and Chaos by Steven H. Strogatz\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probabilistic Models\",\n",
      "            \"resource\": \"Probabilistic Graphical Models: Principles and Techniques by Daphne Koller and Nir Friedman\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Robot Manipulation: Mathematics, Algorithms, and Applications': {\n",
      "    \"Robot Manipulation: Mathematics, Algorithms, and Applications\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Computer Vision\",\n",
      "            \"resource\": \"Computer Vision: Algorithms and Applications by Richard Szeliski\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Sensor Fusion\",\n",
      "            \"resource\": \"Multisensor Data Fusion: From Algorithms and Architectural Design to Applications by H.B. Mitchell\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Robot Manipulation: Mathematics, Algorithms, and Applications': {\n",
      "    \"Robot Manipulation: Mathematics, Algorithms, and Applications\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Computer Vision\",\n",
      "            \"resource\": \"Computer Vision: Algorithms and Applications by Richard Szeliski\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Sensor Fusion\",\n",
      "            \"resource\": \"Multisensor Data Fusion: From Algorithms and Architectural Design to Applications by H.B. Mitchell\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Proximal Policy Optimization Algorithms':Response for resources for paper 'Robotic Grasping and Fine Manipulation': {\n",
      "    \"Robotic Grasping and Fine Manipulation\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Computer Vision\",\n",
      "            \"resource\": \"Computer Vision: Algorithms and Applications by Richard Szeliski\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      " {\n",
      "    \"Proximal Policy Optimization Algorithms\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Theory\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"A First Course in Probability by Sheldon Ross\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Stochastic Processes\",\n",
      "            \"resource\": \"Introduction to Stochastic Processes by Gregory F. Lawler\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Proximal Policy Optimization Algorithms':Response for resources for paper 'Robotic Grasping and Fine Manipulation': {\n",
      "    \"Robotic Grasping and Fine Manipulation\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Computer Vision\",\n",
      "            \"resource\": \"Computer Vision: Algorithms and Applications by Richard Szeliski\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      " {\n",
      "    \"Proximal Policy Optimization Algorithms\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Optimization Theory\",\n",
      "            \"resource\": \"Convex Optimization by Stephen Boyd and Lieven Vandenberghe\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Probability Theory\",\n",
      "            \"resource\": \"A First Course in Probability by Sheldon Ross\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Stochastic Processes\",\n",
      "            \"resource\": \"Introduction to Stochastic Processes by Gregory F. Lawler\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Deep Learning for Robot Learning from Demonstration': {\n",
      "    \"Deep Learning for Robot Learning from Demonstration\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Reinforcement Learning\",\n",
      "            \"resource\": \"Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Computer Vision\",\n",
      "            \"resource\": \"Computer Vision: Algorithms and Applications by Richard Szeliski\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Deep Learning for Robot Learning from Demonstration': {\n",
      "    \"Deep Learning for Robot Learning from Demonstration\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Reinforcement Learning\",\n",
      "            \"resource\": \"Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Computer Vision\",\n",
      "            \"resource\": \"Computer Vision: Algorithms and Applications by Richard Szeliski\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for resources for paper 'Robot Learning from Demonstration': {\n",
      "    \"Robot Learning from Demonstration\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Reinforcement Learning\",\n",
      "            \"resource\": \"Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Computer Vision\",\n",
      "            \"resource\": \"Computer Vision: Algorithms and Applications by Richard Szeliski\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Human-Robot Interaction\",\n",
      "            \"resource\": \"Human-Robot Interaction: An Introduction by Christoph Bartneck, Tony Belpaeme, Friederike Eyssel, Takayuki Kanda, Merel Keijsers, and Selma Šabanović\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "Final Foundational Topics and Recommended Resources:\n",
      "\n",
      "Paper: Reinforcement Learning: An Introduction\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Probability Theory: A First Course in Probability by Sheldon Ross\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Dynamic Programming: Dynamic Programming and Optimal Control by Dimitri P. Bertsekas\n",
      "- Markov Decision Processes: Markov Decision Processes: Discrete Stochastic Dynamic Programming by Martin L. Puterman\n",
      "\n",
      "Paper: Asynchronous Methods for Deep Reinforcement Learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Reinforcement Learning: Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\n",
      "- Optimization Methods: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Stochastic Processes: Introduction to Stochastic Processes by Gregory F. Lawler\n",
      "\n",
      "Paper: Playing Atari with Deep Reinforcement Learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Reinforcement Learning: Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Neural Networks: Neural Networks and Learning Machines by Simon Haykin\n",
      "- Optimization Methods: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "\n",
      "Paper: Human-level Control through Deep Reinforcement Learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Neural Networks: Neural Networks and Learning Machines by Simon Haykin\n",
      "- Optimization Methods: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Markov Decision Processes: Markov Decision Processes: Discrete Stochastic Dynamic Programming by Martin L. Puterman\n",
      "\n",
      "Paper: Deep Reinforcement Learning with Double Q-learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Reinforcement Learning: Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Optimization Theory: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Probability Theory: Probability and Statistics by Morris H. DeGroot and Mark J. Schervish\n",
      "\n",
      "Paper: Algorithms for Reinforcement Learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Probability Theory: A First Course in Probability by Sheldon Ross\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Dynamic Programming: Dynamic Programming and Optimal Control by Dimitri P. Bertsekas\n",
      "\n",
      "Paper: Human-level control through deep reinforcement learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Neuroscience: Principles of Neural Science by Eric R. Kandel, James H. Schwartz, and Thomas M. Jessell\n",
      "- Optimization Theory: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Probability Theory: Probability and Statistics by Morris H. DeGroot and Mark J. Schervish\n",
      "- Computer Vision: Computer Vision: Algorithms and Applications by Richard Szeliski\n",
      "\n",
      "Paper: Proximal Policy Optimization Algorithms\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Optimization Theory: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Probability Theory: A First Course in Probability by Sheldon Ross\n",
      "- Stochastic Processes: Introduction to Stochastic Processes by Gregory F. Lawler\n",
      "\n",
      "Paper: Model-Based Reinforcement Learning: A Survey\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Optimization Theory: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Dynamical Systems: Nonlinear Dynamics and Chaos by Steven H. Strogatz\n",
      "- Probabilistic Models: Probabilistic Graphical Models: Principles and Techniques by Daphne Koller and Nir Friedman\n",
      "\n",
      "Paper: Efficient Exploration in Reinforcement Learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Probability Theory: A First Course in Probability by Sheldon Ross\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Markov Decision Processes: Markov Decision Processes: Discrete Stochastic Dynamic Programming by Martin L. Puterman\n",
      "\n",
      "Paper: Principles of Robot Motion: Theory, Algorithms, and Implementations\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Computer Vision: Computer Vision: Algorithms and Applications by Richard Szeliski\n",
      "- Sensor Fusion: Multisensor Data Fusion: From Algorithms and Architectural Design to Applications by Hassen Fourati\n",
      "- Motion Planning: Planning Algorithms by Steven M. LaValle\n",
      "- Artificial Intelligence: Artificial Intelligence: A Modern Approach by Stuart Russell and Peter Norvig\n",
      "\n",
      "Paper: Learning for Robot Manipulation\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Reinforcement Learning: Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\n",
      "- Computer Vision: Computer Vision: Algorithms and Applications by Richard Szeliski\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "\n",
      "Paper: Robot Manipulation: Mathematics, Algorithms, and Applications\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Computer Vision: Computer Vision: Algorithms and Applications by Richard Szeliski\n",
      "- Sensor Fusion: Multisensor Data Fusion: From Algorithms and Architectural Design to Applications by H.B. Mitchell\n",
      "\n",
      "Paper: Robotic Grasping and Fine Manipulation\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Computer Vision: Computer Vision: Algorithms and Applications by Richard Szeliski\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "\n",
      "Paper: Deep Learning for Robot Learning from Demonstration\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Reinforcement Learning: Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\n",
      "- Computer Vision: Computer Vision: Algorithms and Applications by Richard Szeliski\n",
      "\n",
      "Paper: Robot Learning from Demonstration\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Reinforcement Learning: Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\n",
      "- Computer Vision: Computer Vision: Algorithms and Applications by Richard Szeliski\n",
      "- Human-Robot Interaction: Human-Robot Interaction: An Introduction by Christoph Bartneck, Tony Belpaeme, Friederike Eyssel, Takayuki Kanda, Merel Keijsers, and Selma Šabanović\n",
      "Response for resources for paper 'Robot Learning from Demonstration': {\n",
      "    \"Robot Learning from Demonstration\": [\n",
      "        {\n",
      "            \"topic\": \"Machine Learning\",\n",
      "            \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Robotic Kinematics\",\n",
      "            \"resource\": \"Introduction to Robotics: Mechanics and Control by John J. Craig\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Control Theory\",\n",
      "            \"resource\": \"Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Deep Learning\",\n",
      "            \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Reinforcement Learning\",\n",
      "            \"resource\": \"Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Computer Vision\",\n",
      "            \"resource\": \"Computer Vision: Algorithms and Applications by Richard Szeliski\"\n",
      "        },\n",
      "        {\n",
      "            \"topic\": \"Human-Robot Interaction\",\n",
      "            \"resource\": \"Human-Robot Interaction: An Introduction by Christoph Bartneck, Tony Belpaeme, Friederike Eyssel, Takayuki Kanda, Merel Keijsers, and Selma Šabanović\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "Final Foundational Topics and Recommended Resources:\n",
      "\n",
      "Paper: Reinforcement Learning: An Introduction\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Probability Theory: A First Course in Probability by Sheldon Ross\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Dynamic Programming: Dynamic Programming and Optimal Control by Dimitri P. Bertsekas\n",
      "- Markov Decision Processes: Markov Decision Processes: Discrete Stochastic Dynamic Programming by Martin L. Puterman\n",
      "\n",
      "Paper: Asynchronous Methods for Deep Reinforcement Learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Reinforcement Learning: Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\n",
      "- Optimization Methods: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Stochastic Processes: Introduction to Stochastic Processes by Gregory F. Lawler\n",
      "\n",
      "Paper: Playing Atari with Deep Reinforcement Learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Reinforcement Learning: Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Neural Networks: Neural Networks and Learning Machines by Simon Haykin\n",
      "- Optimization Methods: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "\n",
      "Paper: Human-level Control through Deep Reinforcement Learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Neural Networks: Neural Networks and Learning Machines by Simon Haykin\n",
      "- Optimization Methods: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Markov Decision Processes: Markov Decision Processes: Discrete Stochastic Dynamic Programming by Martin L. Puterman\n",
      "\n",
      "Paper: Deep Reinforcement Learning with Double Q-learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Reinforcement Learning: Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Optimization Theory: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Probability Theory: Probability and Statistics by Morris H. DeGroot and Mark J. Schervish\n",
      "\n",
      "Paper: Algorithms for Reinforcement Learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Probability Theory: A First Course in Probability by Sheldon Ross\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Dynamic Programming: Dynamic Programming and Optimal Control by Dimitri P. Bertsekas\n",
      "\n",
      "Paper: Human-level control through deep reinforcement learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Neuroscience: Principles of Neural Science by Eric R. Kandel, James H. Schwartz, and Thomas M. Jessell\n",
      "- Optimization Theory: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Probability Theory: Probability and Statistics by Morris H. DeGroot and Mark J. Schervish\n",
      "- Computer Vision: Computer Vision: Algorithms and Applications by Richard Szeliski\n",
      "\n",
      "Paper: Proximal Policy Optimization Algorithms\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Optimization Theory: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Probability Theory: A First Course in Probability by Sheldon Ross\n",
      "- Stochastic Processes: Introduction to Stochastic Processes by Gregory F. Lawler\n",
      "\n",
      "Paper: Model-Based Reinforcement Learning: A Survey\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Optimization Theory: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Dynamical Systems: Nonlinear Dynamics and Chaos by Steven H. Strogatz\n",
      "- Probabilistic Models: Probabilistic Graphical Models: Principles and Techniques by Daphne Koller and Nir Friedman\n",
      "\n",
      "Paper: Efficient Exploration in Reinforcement Learning\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Probability Theory: A First Course in Probability by Sheldon Ross\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Markov Decision Processes: Markov Decision Processes: Discrete Stochastic Dynamic Programming by Martin L. Puterman\n",
      "\n",
      "Paper: Principles of Robot Motion: Theory, Algorithms, and Implementations\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Computer Vision: Computer Vision: Algorithms and Applications by Richard Szeliski\n",
      "- Sensor Fusion: Multisensor Data Fusion: From Algorithms and Architectural Design to Applications by Hassen Fourati\n",
      "- Motion Planning: Planning Algorithms by Steven M. LaValle\n",
      "- Artificial Intelligence: Artificial Intelligence: A Modern Approach by Stuart Russell and Peter Norvig\n",
      "\n",
      "Paper: Learning for Robot Manipulation\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Reinforcement Learning: Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\n",
      "- Computer Vision: Computer Vision: Algorithms and Applications by Richard Szeliski\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "\n",
      "Paper: Robot Manipulation: Mathematics, Algorithms, and Applications\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "- Computer Vision: Computer Vision: Algorithms and Applications by Richard Szeliski\n",
      "- Sensor Fusion: Multisensor Data Fusion: From Algorithms and Architectural Design to Applications by H.B. Mitchell\n",
      "\n",
      "Paper: Robotic Grasping and Fine Manipulation\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Computer Vision: Computer Vision: Algorithms and Applications by Richard Szeliski\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Optimization: Convex Optimization by Stephen Boyd and Lieven Vandenberghe\n",
      "\n",
      "Paper: Deep Learning for Robot Learning from Demonstration\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Reinforcement Learning: Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\n",
      "- Computer Vision: Computer Vision: Algorithms and Applications by Richard Szeliski\n",
      "\n",
      "Paper: Robot Learning from Demonstration\n",
      "- Machine Learning: Pattern Recognition and Machine Learning by Christopher M. Bishop\n",
      "- Robotic Kinematics: Introduction to Robotics: Mechanics and Control by John J. Craig\n",
      "- Control Theory: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini\n",
      "- Deep Learning: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
      "- Reinforcement Learning: Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto\n",
      "- Computer Vision: Computer Vision: Algorithms and Applications by Richard Szeliski\n",
      "- Human-Robot Interaction: Human-Robot Interaction: An Introduction by Christoph Bartneck, Tony Belpaeme, Friederike Eyssel, Takayuki Kanda, Merel Keijsers, and Selma Šabanović\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "def find_foundational_topics_and_resources(\n",
    "    pruned_papers, existing_fundamental_concepts\n",
    "):\n",
    "    \"\"\"\n",
    "    Use an LLM agent to identify foundational topics required for the pruned list of papers\n",
    "    and recommend resources for each topic in two passes.\n",
    "    \"\"\"\n",
    "    foundational_topics = {}\n",
    "\n",
    "    def process_paper_for_topics(paper):\n",
    "        input_text = f\"\"\"\n",
    "        The project involves the following paper: {paper}.\n",
    "            Identify all foundational topics required to understand this paper.\n",
    "            Include both the existing foundational topics: {', '.join(existing_fundamental_concepts)}\n",
    "            and any additional foundational topics not listed. \n",
    "            Foundational concepts are foundational to the core concepts ({', '.join(core_concepts)}) and provide the necessary theoretical or technical background \n",
    "            to understand and work with the core concepts. They are more advanced than prerequisites but not as specific as core concepts. \n",
    "            Examples: Machine Learning, Deep Learning, Robotic Kinematics, Control Theory.\n",
    "            Foundational topics should not be too basic either.\n",
    "            Too basic: Linear Algebra, Calculus, Classical Mechanics.\n",
    "            Respond in the following JSON format.\n",
    "            Do NOT include tick marks or any other formatting. Just ONLY provide the JSON object:\n",
    "            {{\n",
    "                \"foundational_topics\": [\n",
    "                    {{\n",
    "                        \"topic\": \"<topic>\"\n",
    "                    }},\n",
    "                    {{\n",
    "                        \"topic\": \"<topic>\"\n",
    "                    }}\n",
    "                ]\n",
    "            }}\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = gpt_agent.query(\"You are a helpful assistant.\", input_text)\n",
    "            print(f\"Response for foundational topics for paper '{paper}':\", response)\n",
    "            response_data = json.loads(response)\n",
    "            return paper, response_data.get(\"foundational_topics\", [])\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating foundational topics for paper '{paper}': {e}\")\n",
    "            return paper, []\n",
    "\n",
    "    def process_paper_for_resources(paper, topics):\n",
    "        input_text = f\"\"\"\n",
    "        The following foundational topics have been identified for the paper '{paper}': {', '.join([t['topic'] for t in topics])}.\n",
    "        For each topic, recommend a research paper, textbook, or resource that provides\n",
    "        a comprehensive introduction to the topic. Respond in the following JSON format\n",
    "        Do NOT include tick marks or any other formatting. Just ONLY provide the JSON object:\n",
    "        {{\n",
    "            \"{paper}\": [\n",
    "                {{\n",
    "                    \"topic\": \"<topic>\",\n",
    "                    \"resource\": \"<resource title and author or link>\"\n",
    "                }},\n",
    "                {{\n",
    "                    \"topic\": \"<topic>\",\n",
    "                    \"resource\": \"<resource title and author or link>\"\n",
    "                }}\n",
    "            ]\n",
    "        }}\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = gpt_agent.query(\"You are a helpful assistant.\", input_text)\n",
    "            print(f\"Response for resources for paper '{paper}':\", response)\n",
    "            response_data = json.loads(response)\n",
    "            return paper, response_data.get(paper, [])\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating resources for paper '{paper}': {e}\")\n",
    "            return paper, []\n",
    "\n",
    "    # First pass: Generate foundational topics grouped by paper\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        future_to_paper = {\n",
    "            executor.submit(process_paper_for_topics, paper): paper\n",
    "            for topic, papers in pruned_papers.items()\n",
    "            for paper in papers\n",
    "        }\n",
    "        for future in future_to_paper:\n",
    "            paper, topics = future.result()\n",
    "            foundational_topics[paper] = topics\n",
    "\n",
    "    # Second pass: Attach resources to each foundational topic\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        future_to_paper = {\n",
    "            executor.submit(process_paper_for_resources, paper, topics): paper\n",
    "            for paper, topics in foundational_topics.items()\n",
    "        }\n",
    "        for future in future_to_paper:\n",
    "            paper, resources = future.result()\n",
    "            foundational_topics[paper] = resources\n",
    "\n",
    "    return foundational_topics\n",
    "\n",
    "\n",
    "# Apply the agent to find foundational topics and resources\n",
    "final_foundational_topics = find_foundational_topics_and_resources(\n",
    "    pruned_selected_papers, fundamental_concepts\n",
    ")\n",
    "\n",
    "# Output the final foundational topics and their resources\n",
    "print(\"\\nFinal Foundational Topics and Recommended Resources:\")\n",
    "for paper, topics in final_foundational_topics.items():\n",
    "    print(f\"\\nPaper: {paper}\")\n",
    "    for topic in topics:\n",
    "        print(f\"- {topic['topic']}: {topic.get('resource', 'No resource available')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 1 column 356 (char 355)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     54\u001b[39m G = build_tree_graph(\n\u001b[32m     55\u001b[39m     project_title,\n\u001b[32m     56\u001b[39m     core_concepts,\n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m     paper_metadata,\n\u001b[32m     60\u001b[39m )\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Visualize with pyvis\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[43mvisualize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/cal/294/research-ramp/src/utils/visualization.py:24\u001b[39m, in \u001b[36mvisualize\u001b[39m\u001b[34m(G, output_file)\u001b[39m\n\u001b[32m     21\u001b[39m     net.add_edge(source, target)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Disable hierarchical layout and enable physics for free movement in all directions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m     26\u001b[39m \u001b[33;43;03m    {\u001b[39;49;00m\n\u001b[32m     27\u001b[39m \u001b[33;43;03m      \"layout\": {\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[33;43;03m        \"hierarchical\": {\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[33;43;03m          \"enabled\": true\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[33;43;03m        }\u001b[39;49;00m\n\u001b[32m     31\u001b[39m \u001b[33;43;03m      },\u001b[39;49;00m\n\u001b[32m     32\u001b[39m \u001b[33;43;03m      \"nodes\": {\u001b[39;49;00m\n\u001b[32m     33\u001b[39m \u001b[33;43;03m        \"font\": {\u001b[39;49;00m\n\u001b[32m     34\u001b[39m \u001b[33;43;03m          \"multi\": true,\u001b[39;49;00m\n\u001b[32m     35\u001b[39m \u001b[33;43;03m          \"size\": 10\u001b[39;49;00m\n\u001b[32m     36\u001b[39m \u001b[33;43;03m        },\u001b[39;49;00m\n\u001b[32m     37\u001b[39m \u001b[33;43;03m        \"size\": 15,\u001b[39;49;00m\n\u001b[32m     38\u001b[39m \u001b[33;43;03m        \"shape\": \"box\",\u001b[39;49;00m\n\u001b[32m     39\u001b[39m \u001b[33;43;03m        \"widthConstraint\": {\u001b[39;49;00m\n\u001b[32m     40\u001b[39m \u001b[33;43;03m          \"maximum\": 200\u001b[39;49;00m\n\u001b[32m     41\u001b[39m \u001b[33;43;03m        }\u001b[39;49;00m\n\u001b[32m     42\u001b[39m \u001b[33;43;03m      },\u001b[39;49;00m\n\u001b[32m     43\u001b[39m \u001b[33;43;03m      \"interaction\": {\u001b[39;49;00m\n\u001b[32m     44\u001b[39m \u001b[33;43;03m        \"hover\": true,\u001b[39;49;00m\n\u001b[32m     45\u001b[39m \u001b[33;43;03m        \"dragNodes\": true,\u001b[39;49;00m\n\u001b[32m     46\u001b[39m \u001b[33;43;03m        \"selectConnectedEdges\": false\u001b[39;49;00m\n\u001b[32m     47\u001b[39m \u001b[33;43;03m      },\u001b[39;49;00m\n\u001b[32m     48\u001b[39m \u001b[33;43;03m      \"physics\": {\u001b[39;49;00m\n\u001b[32m     49\u001b[39m \u001b[33;43;03m        \"enabled\": true,\u001b[39;49;00m\n\u001b[32m     50\u001b[39m \u001b[33;43;03m        \"stabilization\": {\u001b[39;49;00m\n\u001b[32m     51\u001b[39m \u001b[33;43;03m          \"enabled\": true\u001b[39;49;00m\n\u001b[32m     52\u001b[39m \u001b[33;43;03m        },\u001b[39;49;00m\n\u001b[32m     53\u001b[39m \u001b[33;43;03m        \"solver\": \"forceAtlas2Based\",\u001b[39;49;00m\n\u001b[32m     54\u001b[39m \u001b[33;43;03m        \"forceAtlas2Based\": {\u001b[39;49;00m\n\u001b[32m     55\u001b[39m \u001b[33;43;03m          \"gravitationalConstant\": -200,  // Increase repulsion\u001b[39;49;00m\n\u001b[32m     56\u001b[39m \u001b[33;43;03m          \"centralGravity\": 0.01,\u001b[39;49;00m\n\u001b[32m     57\u001b[39m \u001b[33;43;03m          \"springLength\": 200,           // Increase spring length\u001b[39;49;00m\n\u001b[32m     58\u001b[39m \u001b[33;43;03m          \"springConstant\": 0.05         // Decrease spring stiffness for more spread\u001b[39;49;00m\n\u001b[32m     59\u001b[39m \u001b[33;43;03m        },\u001b[39;49;00m\n\u001b[32m     60\u001b[39m \u001b[33;43;03m        \"minVelocity\": 0.75\u001b[39;49;00m\n\u001b[32m     61\u001b[39m \u001b[33;43;03m      }\u001b[39;49;00m\n\u001b[32m     62\u001b[39m \u001b[33;43;03m    }\u001b[39;49;00m\n\u001b[32m     63\u001b[39m \u001b[33;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[32m     64\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m net.show(output_file)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/cal/294/research-ramp/.venv/lib/python3.12/site-packages/pyvis/network.py:1006\u001b[39m, in \u001b[36mNetwork.set_options\u001b[39m\u001b[34m(self, options)\u001b[39m\n\u001b[32m    996\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_options\u001b[39m(\u001b[38;5;28mself\u001b[39m, options):\n\u001b[32m    997\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    998\u001b[39m \u001b[33;03m    Overrides the default options object passed to the VisJS framework.\u001b[39;00m\n\u001b[32m    999\u001b[39m \u001b[33;03m    Delegates to the :meth:`options.Options.set` routine.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1004\u001b[39m \u001b[33;03m    :type options: str\u001b[39;00m\n\u001b[32m   1005\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1006\u001b[39m     \u001b[38;5;28mself\u001b[39m.options = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/cal/294/research-ramp/.venv/lib/python3.12/site-packages/pyvis/options.py:224\u001b[39m, in \u001b[36mOptions.set\u001b[39m\u001b[34m(self, new_options)\u001b[39m\n\u001b[32m    222\u001b[39m first_bracket = options.find(\u001b[33m\"\u001b[39m\u001b[33m{\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    223\u001b[39m options = options[first_bracket:]\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m options = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m options\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     end = _w(s, end).end()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py:353\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[33;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[33;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    350\u001b[39m \n\u001b[32m    351\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting property name enclosed in double quotes: line 1 column 356 (char 355)"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import utils\n",
    "\n",
    "import importlib\n",
    "importlib.reload(utils.visualization)\n",
    "from utils.tree_builder import build_tree_graph\n",
    "from utils.visualization import visualize\n",
    "\n",
    "\n",
    "# project_title = \"Title of the Project\"\n",
    "# core_concepts = [\"Reinforcement Learning\"]\n",
    "# pruned_selected_papers = {\n",
    "#     \"Reinforcement Learning\": [\n",
    "#         \"Reinforcement Learning: An Introduction\",\n",
    "#         \"Human-level control through deep reinforcement learning\",\n",
    "#     ]\n",
    "# }\n",
    "# foundational_topics = {\n",
    "#     \"Reinforcement Learning: An Introduction\": [\n",
    "#         {\n",
    "#             \"topic\": \"Machine Learning Basics\",\n",
    "#             \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\",\n",
    "#         },\n",
    "#         {\n",
    "#             \"topic\": \"Neural Networks\",\n",
    "#             \"resource\": \"Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\",\n",
    "#         },\n",
    "#     ],\n",
    "#     \"Human-level control through deep reinforcement learning\": [\n",
    "#         {\n",
    "#             \"topic\": \"Machine Learning Basics\",\n",
    "#             \"resource\": \"Pattern Recognition and Machine Learning by Christopher M. Bishop\",\n",
    "#         }\n",
    "#     ],\n",
    "# }\n",
    "\n",
    "paper_metadata = {\n",
    "    \"Reinforcement Learning: An Introduction\": {\n",
    "        \"authors\": \"Richard S. Sutton, Andrew G. Barto\",\n",
    "        \"year\": 1998,\n",
    "        \"doi\": \"10.1109/9780470544787\",\n",
    "        \"url\": \"https://example.com/reinforcement-learning-introduction\",\n",
    "    },\n",
    "    \"Human-level control through deep reinforcement learning\": {\n",
    "        \"authors\": \"Volodymyr Mnih, Koray Kavukcuoglu, David Silver, et al.\",\n",
    "        \"year\": 2015,\n",
    "        \"doi\": \"10.1038/nature14236\",\n",
    "        \"url\": \"https://example.com/human-level-control\",\n",
    "    },\n",
    "}\n",
    "\n",
    "G = build_tree_graph(\n",
    "    project_title,\n",
    "    core_concepts,\n",
    "    pruned_selected_papers,\n",
    "    final_foundational_topics,\n",
    "    paper_metadata,\n",
    ")\n",
    "\n",
    "# Visualize with pyvis\n",
    "visualize(G)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
