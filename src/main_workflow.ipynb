{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from agents.general_agent import Agent\n",
    "from agents.eval_agent import EvalAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inline implementation of ConceptExtractionAgent for debugging\n",
    "class ConceptExtractionAgent:\n",
    "    def __init__(self, gpt_agent, queries_folder=\"queries\"):\n",
    "        self.gpt_agent = gpt_agent\n",
    "        self.queries_folder = queries_folder\n",
    "\n",
    "    def extract_concepts(self, filename):\n",
    "        \"\"\"\n",
    "        Extract concepts from a project description using GPT API.\n",
    "        \"\"\"\n",
    "        file_path = os.path.join(self.queries_folder, filename)\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File {file_path} not found.\")\n",
    "\n",
    "        with open(file_path, \"r\") as file:\n",
    "            project_data = json.load(file)\n",
    "\n",
    "        # Extract the project description\n",
    "        description = project_data.get(\"description\", \"\")\n",
    "        if not description:\n",
    "            raise ValueError(\"Project description is missing in the JSON file.\")\n",
    "\n",
    "        # Query GPT to infer concepts\n",
    "        return self._query_gpt_for_concepts(description)\n",
    "\n",
    "    def _query_gpt_for_concepts(self, description):\n",
    "        \"\"\"\n",
    "        Query GPT to infer concepts from the project description.\n",
    "        \"\"\"\n",
    "        input_text = f\"\"\"\n",
    "        Analyze the following project description and extract concepts into four categories. \n",
    "        Each category has specific guidelines to ensure proper classification:\n",
    "\n",
    "        - Fundamental Concepts: These are foundational to the core concepts and provide the necessary theoretical or technical background \n",
    "          to understand and work with the core concepts. They are more advanced than prerequisites but not as specific as core concepts. \n",
    "          Examples: Machine Learning Basics, Deep Learning, Robotic Kinematics, Control Theory.\n",
    "\n",
    "        - Core Concepts: These are the central focus areas of the project and represent the main topics or themes the project is addressing. \n",
    "          They are typically the tags or keywords associated with the project. \n",
    "          Examples: Reinforcement Learning (RL), Computer Vision, Robotics.\n",
    "\n",
    "        - Specialized Concepts: These are specific applications or implementations of the core concepts within the context of the project. \n",
    "          They are highly specific and often represent advanced or applied topics. \n",
    "          Examples: RL for Grasping Strategies, Sim-to-Real Transfer, Affordance-Based Manipulation.\n",
    "\n",
    "        Project Description:\n",
    "        {description}\n",
    "\n",
    "        Provide the output in the following JSON format.\n",
    "        Do NOT include tick marks or any other formatting. Just ONLY provide the JSON object:\n",
    "        {{\n",
    "            \"prerequisites\": [\"<list of concepts>\"],\n",
    "            \"fundamental_concepts\": [\"<list of concepts>\"],\n",
    "            \"core_concepts\": [\"<list of concepts>\"],\n",
    "            \"specialized_concepts\": [\"<list of concepts>\"]\n",
    "        }}\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.gpt_agent.query(\"You are a helpful assistant.\", input_text)\n",
    "            print(\"GPT response:\", response)  # Debugging line\n",
    "            return json.loads(response)\n",
    "        except json.JSONDecodeError:\n",
    "            raise ValueError(\n",
    "                \"Failed to parse GPT response. Ensure the response is in the correct JSON format.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT response: {\n",
      "    \"prerequisites\": [\"Programming\", \"Basic Physics\"],\n",
      "    \"fundamental_concepts\": [\"Machine Learning Basics\", \"Robotic Kinematics\", \"Control Theory\"],\n",
      "    \"core_concepts\": [\"Reinforcement Learning\", \"Robotics\", \"Computer Vision\"],\n",
      "    \"specialized_concepts\": [\"RL for Grasping Strategies\", \"Sim-to-Real Transfer\", \"Affordance-Based Manipulation\", \"Pick-and-Place Tasks\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "queries_folder = os.path.join(notebook_dir, \"..\", \"queries\")\n",
    "\n",
    "gpt_agent = Agent(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "concept_agent = ConceptExtractionAgent(gpt_agent, queries_folder=queries_folder)\n",
    "\n",
    "try:\n",
    "    concepts = concept_agent.extract_concepts(\"robotics_grasp.json\")\n",
    "    core_concepts = concepts[\"core_concepts\"]\n",
    "    specialized_concepts = concepts[\"specialized_concepts\"]\n",
    "    fundamental_concepts = concepts[\"fundamental_concepts\"]\n",
    "    prerequisites = concepts[\"prerequisites\"]\n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    core_concepts = []\n",
    "    specialized_concepts = []\n",
    "    fundamental_concepts = []\n",
    "    prerequisites = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_gpt_for_survey_papers(concept):\n",
    "    \"\"\"\n",
    "    Query GPT-4 to get survey papers for a given concept.\n",
    "    \"\"\"\n",
    "    instructions = \"You are a helpful assistant.\"\n",
    "    input_text = f\"Provide 4 survey papers on the topic '{concept}'. For each paper, include the title and Semantic Scholar DOI.\"\n",
    "    return gpt_agent.query(instructions, input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying GPT-4 for survey papers on: Reinforcement Learning (RL)\n",
      "GPT-4 Response for Reinforcement Learning (RL):\n",
      "{\n",
      "    \"papers\": [\n",
      "        {\n",
      "            \"title\": \"A Survey of Reinforcement Learning Algorithms for Dynamically Varying Environments\",\n",
      "            \"doi\": \"10.1109/ACCESS.2020.3019890\",\n",
      "            \"url\": \"https://ieeexplore.ieee.org/document/9174910\",\n",
      "            \"abstract\": \"This paper surveys reinforcement learning algorithms that adapt to dynamically changing environments, focusing on methods that adjust to new conditions without retraining from scratch.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Deep Reinforcement Learning: A Survey\",\n",
      "            \"doi\": \"10.1145/3386252\",\n",
      "            \"url\": \"https://dl.acm.org/doi/10.1145/3386252\",\n",
      "            \"abstract\": \"This survey provides a comprehensive overview of deep reinforcement learning, discussing key algorithms, theoretical foundations, and applications across various domains.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey on Multi-Agent Reinforcement Learning: From Foundations to Applications\",\n",
      "            \"doi\": \"10.1109/TCYB.2020.3045894\",\n",
      "            \"url\": \"https://ieeexplore.ieee.org/document/9318942\",\n",
      "            \"abstract\": \"This paper reviews multi-agent reinforcement learning, covering foundational concepts, algorithmic developments, and practical applications in complex environments.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey of Inverse Reinforcement Learning: Challenges, Methods and Progress\",\n",
      "            \"doi\": \"10.1016/j.artint.2020.103500\",\n",
      "            \"url\": \"https://www.sciencedirect.com/science/article/pii/S0004370220301535\",\n",
      "            \"abstract\": \"This survey explores inverse reinforcement learning, highlighting the challenges, methodologies, and recent advancements in the field.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey on Safe Reinforcement Learning: Methods, Challenges, and Future Directions\",\n",
      "            \"doi\": \"10.1109/ACCESS.2020.3045430\",\n",
      "            \"url\": \"https://ieeexplore.ieee.org/document/9318943\",\n",
      "            \"abstract\": \"This paper surveys safe reinforcement learning, focusing on methods that ensure safety during learning and deployment, and discusses future research directions.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey of Model-Based Reinforcement Learning: Recent Advances and Applications\",\n",
      "            \"doi\": \"10.1109/ACCESS.2021.3058843\",\n",
      "            \"url\": \"https://ieeexplore.ieee.org/document/9355273\",\n",
      "            \"abstract\": \"This survey reviews model-based reinforcement learning, discussing recent advances, key challenges, and applications in various fields.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Querying GPT-4 for survey papers on: Computer Vision\n",
      "GPT-4 Response for Computer Vision:\n",
      "{\n",
      "    \"papers\": [\n",
      "        {\n",
      "            \"title\": \"Deep Learning for Computer Vision: A Brief Review\",\n",
      "            \"doi\": \"10.1109/ACCESS.2018.2832181\",\n",
      "            \"url\": \"https://ieeexplore.ieee.org/document/8354201\",\n",
      "            \"abstract\": \"This paper provides a comprehensive review of deep learning techniques applied to computer vision tasks, highlighting recent advancements and challenges.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey on Image Data Augmentation for Deep Learning\",\n",
      "            \"doi\": \"10.1109/ACCESS.2019.2895240\",\n",
      "            \"url\": \"https://ieeexplore.ieee.org/document/8632683\",\n",
      "            \"abstract\": \"This survey reviews various image data augmentation techniques used to improve the performance of deep learning models in computer vision.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey on Visual Transformer Models\",\n",
      "            \"doi\": \"10.1016/j.patcog.2021.107377\",\n",
      "            \"url\": \"https://www.sciencedirect.com/science/article/pii/S0031320321003640\",\n",
      "            \"abstract\": \"This paper surveys the application of transformer models in computer vision, discussing their architecture, advantages, and limitations.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Comprehensive Review on Object Detection in Aerial Images\",\n",
      "            \"doi\": \"10.1016/j.isprsjprs.2020.11.006\",\n",
      "            \"url\": \"https://www.sciencedirect.com/science/article/pii/S0924271620303115\",\n",
      "            \"abstract\": \"This review focuses on object detection techniques in aerial images, covering traditional methods and recent deep learning approaches.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey on 3D Shape Analysis in Computer Vision\",\n",
      "            \"doi\": \"10.1016/j.cviu.2019.102898\",\n",
      "            \"url\": \"https://www.sciencedirect.com/science/article/pii/S1077314219301555\",\n",
      "            \"abstract\": \"This survey provides an overview of 3D shape analysis techniques in computer vision, including shape representation, matching, and retrieval.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"A Survey on Image Captioning: Convergence of Vision and Language\",\n",
      "            \"doi\": \"10.1109/ACCESS.2020.2976654\",\n",
      "            \"url\": \"https://ieeexplore.ieee.org/document/8998255\",\n",
      "            \"abstract\": \"This paper surveys image captioning techniques, exploring the integration of computer vision and natural language processing to generate descriptive text for images.\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Query GPT-4 for survey papers for each core concept\n",
    "survey_papers = {}\n",
    "for concept in core_concepts:\n",
    "    print(f\"Querying GPT-4 for survey papers on: {concept}\")\n",
    "    \n",
    "    input_text = f\"\"\"\n",
    "    Provide 6 survey papers on the topic '{concept}' along with their DOI id's, URLs, and other metadata in the following JSON format.\n",
    "    Do NOT include tick marks or any other formatting. Just ONLY provide the JSON object: \n",
    "    {{\n",
    "        \"papers\": [\n",
    "            {{\n",
    "                \"title\": \"<title>\",\n",
    "                \"doi\": \"<doi>\",\n",
    "                \"url\": \"<url>\",\n",
    "                \"abstract\": \"<abstract>\"\n",
    "            }},\n",
    "            ...\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        gpt_response = gpt_agent.query(\"You are a helpful assistant.\", input_text)\n",
    "        print(f\"GPT-4 Response for {concept}:\\n{json.dumps(json.loads(gpt_response), indent=4)}\")\n",
    "        survey_papers[concept] = json.loads(gpt_response)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Failed to parse GPT-4 response for {concept}. Response: {gpt_response}\")\n",
    "        survey_papers[concept] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing concept: Reinforcement Learning (RL)\n",
      "Retrieving top references for paper: A Survey of Reinforcement Learning Algorithms for Dynamically Varying Environments\n",
      "Retrieving top references for paper: Deep Reinforcement Learning: A Survey\n",
      "Retrieving top references for paper: A Survey on Multi-Agent Reinforcement Learning: From Foundations to Applications\n",
      "Retrieving top references for paper: A Survey of Inverse Reinforcement Learning: Challenges, Methods and Progress\n",
      "Retrieving top references for paper: A Survey on Safe Reinforcement Learning: Methods, Challenges, and Future Directions\n",
      "Retrieving top references for paper: A Survey of Model-Based Reinforcement Learning: Recent Advances and Applications\n",
      "\n",
      "Seminal Paper Counts for Reinforcement Learning (RL) (sorted by count):\n",
      "Reinforcement Learning: An Introduction: 5\n",
      "Dynamic Environments and Reinforcement Learning: 1\n",
      "Algorithms for Adaptive Learning in Non-Stationary Environments: 1\n",
      "Deep Reinforcement Learning with Non-Stationary Rewards: 1\n",
      "Meta-Learning for Dynamic Environments: 1\n",
      "Playing Atari with Deep Reinforcement Learning: 1\n",
      "Human-level control through deep reinforcement learning: 1\n",
      "Asynchronous Methods for Deep Reinforcement Learning: 1\n",
      "Proximal Policy Optimization Algorithms: 1\n",
      "Multi-Agent Systems: Algorithmic, Game-Theoretic, and Logical Foundations: 1\n",
      "A Survey of Multi-Agent Reinforcement Learning: 1\n",
      "Cooperative Multi-Agent Reinforcement Learning: A Survey: 1\n",
      "Deep Reinforcement Learning with Double Q-learning: 1\n",
      "Algorithms for Inverse Reinforcement Learning: 1\n",
      "Apprenticeship Learning via Inverse Reinforcement Learning: 1\n",
      "Maximum Entropy Inverse Reinforcement Learning: 1\n",
      "Inverse Reinforcement Learning with Gaussian Processes: 1\n",
      "Deep Inverse Reinforcement Learning: 1\n",
      "Safe Exploration in Reinforcement Learning: 1\n",
      "Constrained Policy Optimization: 1\n",
      "Safe Reinforcement Learning via Shielding: 1\n",
      "A Survey of Safe Reinforcement Learning: 1\n",
      "Model-Based Reinforcement Learning with Continuous States and Actions: 1\n",
      "Deep Reinforcement Learning: A Survey: 1\n",
      "Model-Based Reinforcement Learning: A Survey: 1\n",
      "Advances in Model-Based Reinforcement Learning: 1\n",
      "\n",
      "Processing concept: Computer Vision\n",
      "Retrieving top references for paper: Deep Learning for Computer Vision: A Brief Review\n",
      "Retrieving top references for paper: A Survey on Image Data Augmentation for Deep Learning\n",
      "Retrieving top references for paper: A Survey on Visual Transformer Models\n",
      "Retrieving top references for paper: A Comprehensive Review on Object Detection in Aerial Images\n",
      "Retrieving top references for paper: A Survey on 3D Shape Analysis in Computer Vision\n",
      "Retrieving top references for paper: A Survey on Image Captioning: Convergence of Vision and Language\n",
      "\n",
      "Seminal Paper Counts for Computer Vision (sorted by count):\n",
      "Deep Learning: 3\n",
      "ImageNet Classification with Deep Convolutional Neural Networks: 2\n",
      "ImageNet: A Large-Scale Hierarchical Image Database: 2\n",
      "Deep Residual Learning for Image Recognition: 1\n",
      "Very Deep Convolutional Networks for Large-Scale Image Recognition: 1\n",
      "Generative Adversarial Nets: 1\n",
      "AlexNet: ImageNet Classification with Deep Convolutional Neural Networks: 1\n",
      "Generative Adversarial Networks: 1\n",
      "AutoAugment: Learning Augmentation Policies from Data: 1\n",
      "Attention Is All You Need: 1\n",
      "Visual Transformer: A Survey: 1\n",
      "Vision Transformers: A Comprehensive Review: 1\n",
      "Object Detection in Aerial Imagery: A Survey: 1\n",
      "Deep Learning for Object Detection: A Comprehensive Review: 1\n",
      "YOLO: Real-Time Object Detection: 1\n",
      "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks: 1\n",
      "Aerial Image Analysis: Techniques and Applications: 1\n",
      "3D Shape Analysis: A Survey: 1\n",
      "Geometric Methods in Shape Analysis: 1\n",
      "Shape Matching and Object Recognition Using Shape Contexts: 1\n",
      "Deep Learning for 3D Shape Analysis: 1\n",
      "A Comprehensive Guide to 3D Shape Descriptors: 1\n",
      "Show and Tell: A Neural Image Caption Generator: 1\n",
      "Deep Visual-Semantic Alignments for Generating Image Descriptions: 1\n",
      "Attention is All You Need: 1\n",
      "Neural Machine Translation by Jointly Learning to Align and Translate: 1\n"
     ]
    }
   ],
   "source": [
    "# Separate dictionaries for seminal paper counts by topic\n",
    "seminal_paper_counts_by_topic = {}\n",
    "\n",
    "# Initialize top_references as an empty dictionary\n",
    "top_references = {}\n",
    "\n",
    "for concept, papers in survey_papers.items():\n",
    "    print(f\"\\nProcessing concept: {concept}\")\n",
    "    top_references[concept] = {}\n",
    "    seminal_paper_counts_by_topic[concept] = {}\n",
    "\n",
    "    for paper in papers.get(\"papers\", []):\n",
    "        title = paper.get(\"title\", \"Unknown Title\")\n",
    "        print(f\"Retrieving top references for paper: {title}\")\n",
    "        \n",
    "        input_text = f\"\"\"\n",
    "        For the paper titled '{title}', provide the 5 most seminal works (including papers and textbooks) in the field that are related to this paper and would likely be cited. \n",
    "        If you cannot access external databases, respond with 5 hypothetical seminal works based on the paper title in the following example JSON format (not with this content, but with the same structure):\n",
    "        Do NOT include tick marks or any other formatting. Just ONLY provide the JSON object: \n",
    "        {{\n",
    "            \"seminal_works\": [\n",
    "            {{\"title\": \"Seminal Work 1\", \"year\": 1998}},\n",
    "            {{\"title\": \"Seminal Work 2\", \"year\": 2013}},\n",
    "            {{\"title\": \"Seminal Work 3\", \"year\": 2015}},\n",
    "            {{\"title\": \"Seminal Work 4\", \"year\": 2020}},\n",
    "            {{\"title\": \"Seminal Work 5\", \"year\": 2021}}\n",
    "            ]\n",
    "        }}\n",
    "        \"\"\"\n",
    "        try:\n",
    "            gpt_response = gpt_agent.query(\"You are a helpful assistant.\", input_text)\n",
    "            references = json.loads(gpt_response).get(\"seminal_works\", [])\n",
    "            top_references[concept][title] = references\n",
    "            paper[\"references\"] = references\n",
    "            \n",
    "            # Aggregate references into the topic-specific seminal paper counts\n",
    "            for ref in references:\n",
    "                ref_title = ref[\"title\"]\n",
    "                if ref_title in seminal_paper_counts_by_topic[concept]:\n",
    "                    seminal_paper_counts_by_topic[concept][ref_title] += 1\n",
    "                else:\n",
    "                    seminal_paper_counts_by_topic[concept][ref_title] = 1\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Failed to parse GPT-4 response for paper: {title}\")\n",
    "            top_references[concept][title] = []\n",
    "            paper[\"references\"] = []\n",
    "    \n",
    "    # Output the seminal paper counts for the current topic by value\n",
    "    print(f\"\\nSeminal Paper Counts for {concept} (sorted by count):\")\n",
    "    sorted_counts = sorted(seminal_paper_counts_by_topic[concept].items(), key=lambda item: item[1], reverse=True)\n",
    "    for paper_title, count in sorted_counts:\n",
    "        print(f\"{paper_title}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected Papers for Evaluation:\n",
      "\n",
      "Topic: Reinforcement Learning (RL)\n",
      "- Reinforcement Learning: An Introduction\n",
      "- Dynamic Environments and Reinforcement Learning\n",
      "- Algorithms for Adaptive Learning in Non-Stationary Environments\n",
      "- Deep Reinforcement Learning with Non-Stationary Rewards\n",
      "- Meta-Learning for Dynamic Environments\n",
      "- Playing Atari with Deep Reinforcement Learning\n",
      "- Human-level control through deep reinforcement learning\n",
      "- Asynchronous Methods for Deep Reinforcement Learning\n",
      "\n",
      "Topic: Computer Vision\n",
      "- ImageNet Classification with Deep Convolutional Neural Networks\n",
      "- Deep Learning\n",
      "- ImageNet: A Large-Scale Hierarchical Image Database\n",
      "- Deep Residual Learning for Image Recognition\n",
      "- Very Deep Convolutional Networks for Large-Scale Image Recognition\n",
      "- Generative Adversarial Nets\n",
      "- AlexNet: ImageNet Classification with Deep Convolutional Neural Networks\n",
      "- Generative Adversarial Networks\n",
      "- AutoAugment: Learning Augmentation Policies from Data\n"
     ]
    }
   ],
   "source": [
    "# Initialize the evaluation agent\n",
    "eval_agent = EvalAgent(seminal_paper_counts_by_topic)\n",
    "\n",
    "# Select papers based on the criteria\n",
    "selected_papers = eval_agent.select_papers()\n",
    "\n",
    "# Output the selected papers for evaluation\n",
    "print(\"\\nSelected Papers for Evaluation:\")\n",
    "for topic, papers in selected_papers.items():\n",
    "    print(f\"\\nTopic: {topic}\")\n",
    "    for paper in papers:\n",
    "        print(f\"- {paper}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
