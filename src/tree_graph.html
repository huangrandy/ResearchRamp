<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 600px;
                 background-color: #ffffff;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             

             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"group": "root", "id": "Robotic Manipulation in Unstructured Environments", "label": "Robotic Manipulation in Unstructured Environments", "shape": "dot", "title": "Project Title: Robotic Manipulation in Unstructured Environments"}, {"group": "Reinforcement Learning", "id": "Reinforcement Learning", "label": "Reinforcement Learning", "shape": "dot", "title": "Core Concept: Reinforcement Learning"}, {"group": "Reinforcement Learning", "id": "Reinforcement Learning: An Introduction", "label": "Reinforcement Learning: An Introduction", "shape": "dot", "title": "Paper: Reinforcement Learning: An Introduction\nAuthors: Richard S. Sutton, Andrew G. Barto\nYear: 1998\nDOI: 10.1109/9780470544787\nURL: https://example.com/reinforcement-learning-introduction"}, {"group": "Reinforcement Learning", "id": "Machine Learning Basics", "label": "Machine Learning Basics", "shape": "dot", "title": "Foundational Topic: Machine Learning Basics\nResource: Pattern Recognition and Machine Learning by Christopher M. Bishop"}, {"group": "Reinforcement Learning", "id": "Robotic Kinematics", "label": "Robotic Kinematics", "shape": "dot", "title": "Foundational Topic: Robotic Kinematics\nResource: Introduction to Robotics: Mechanics and Control by John J. Craig"}, {"group": "Reinforcement Learning", "id": "Control Theory", "label": "Control Theory", "shape": "dot", "title": "Foundational Topic: Control Theory\nResource: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini"}, {"group": "Reinforcement Learning", "id": "Probability Theory", "label": "Probability Theory", "shape": "dot", "title": "Foundational Topic: Probability Theory\nResource: A First Course in Probability by Sheldon Ross"}, {"group": "Reinforcement Learning", "id": "Markov Decision Processes", "label": "Markov Decision Processes", "shape": "dot", "title": "Foundational Topic: Markov Decision Processes\nResource: Markov Decision Processes: Discrete Stochastic Dynamic Programming by Martin L. Puterman"}, {"group": "Reinforcement Learning", "id": "Dynamic Programming", "label": "Dynamic Programming", "shape": "dot", "title": "Foundational Topic: Dynamic Programming\nResource: Dynamic Programming and Optimal Control by Dimitri P. Bertsekas"}, {"group": "Reinforcement Learning", "id": "Stochastic Processes", "label": "Stochastic Processes", "shape": "dot", "title": "Foundational Topic: Stochastic Processes\nResource: Introduction to Stochastic Processes by Gregory F. Lawler"}, {"group": "Reinforcement Learning", "id": "Optimization", "label": "Optimization", "shape": "dot", "title": "Foundational Topic: Optimization\nResource: Convex Optimization by Stephen Boyd and Lieven Vandenberghe"}, {"group": "Reinforcement Learning", "id": "Human-level control through deep reinforcement learning", "label": "Human-level control through deep reinforcement learning", "shape": "dot", "title": "Paper: Human-level control through deep reinforcement learning\nAuthors: Volodymyr Mnih, Koray Kavukcuoglu, David Silver, et al.\nYear: 2015\nDOI: 10.1038/nature14236\nURL: https://example.com/human-level-control"}, {"group": "Reinforcement Learning", "id": "Deep Learning", "label": "Deep Learning", "shape": "dot", "title": "Foundational Topic: Deep Learning\nResource: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville"}, {"group": "Reinforcement Learning", "id": "Neural Networks", "label": "Neural Networks", "shape": "dot", "title": "Foundational Topic: Neural Networks\nResource: Neural Networks and Learning Machines by Simon Haykin"}, {"group": "Reinforcement Learning", "id": "Optimization Algorithms", "label": "Optimization Algorithms", "shape": "dot", "title": "Foundational Topic: Optimization Algorithms\nResource: Convex Optimization by Stephen Boyd and Lieven Vandenberghe"}, {"group": "Reinforcement Learning", "id": "Game Theory", "label": "Game Theory", "shape": "dot", "title": "Foundational Topic: Game Theory\nResource: An Introduction to Game Theory by Martin J. Osborne"}, {"group": "Reinforcement Learning", "id": "Asynchronous Methods for Deep Reinforcement Learning", "label": "Asynchronous Methods for Deep Reinforcement Learning", "shape": "dot", "title": "Paper: Asynchronous Methods for Deep Reinforcement Learning\nAuthors: Unknown\nYear: Unknown\nDOI: N/A\nURL: N/A"}, {"group": "Reinforcement Learning", "id": "Parallel Computing", "label": "Parallel Computing", "shape": "dot", "title": "Foundational Topic: Parallel Computing\nResource: Parallel Programming: Techniques and Applications Using Networked Workstations and Parallel Computers by Barry Wilkinson and Michael Allen"}, {"group": "Reinforcement Learning", "id": "Proximal Policy Optimization Algorithms", "label": "Proximal Policy Optimization Algorithms", "shape": "dot", "title": "Paper: Proximal Policy Optimization Algorithms\nAuthors: Unknown\nYear: Unknown\nDOI: N/A\nURL: N/A"}, {"group": "Reinforcement Learning", "id": "Probability and Statistics", "label": "Probability and Statistics", "shape": "dot", "title": "Foundational Topic: Probability and Statistics\nResource: Probability and Statistics for Engineers and Scientists by Ronald E. Walpole, Raymond H. Myers, Sharon L. Myers, and Keying E. Ye"}, {"group": "Reinforcement Learning", "id": "Gradient Descent", "label": "Gradient Descent", "shape": "dot", "title": "Foundational Topic: Gradient Descent\nResource: Numerical Optimization by Jorge Nocedal and Stephen J. Wright"}, {"group": "Reinforcement Learning", "id": "Policy Gradient Methods", "label": "Policy Gradient Methods", "shape": "dot", "title": "Foundational Topic: Policy Gradient Methods\nResource: Policy Gradient Methods for Reinforcement Learning with Function Approximation by Richard S. Sutton, David McAllester, Satinder Singh, and Yishay Mansour"}, {"group": "Reinforcement Learning", "id": "Playing Atari with Deep Reinforcement Learning", "label": "Playing Atari with Deep Reinforcement Learning", "shape": "dot", "title": "Paper: Playing Atari with Deep Reinforcement Learning\nAuthors: Unknown\nYear: Unknown\nDOI: N/A\nURL: N/A"}, {"group": "Reinforcement Learning", "id": "Q-Learning", "label": "Q-Learning", "shape": "dot", "title": "Foundational Topic: Q-Learning\nResource: Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto"}, {"group": "Reinforcement Learning", "id": "Optimization Techniques", "label": "Optimization Techniques", "shape": "dot", "title": "Foundational Topic: Optimization Techniques\nResource: Convex Optimization by Stephen Boyd and Lieven Vandenberghe"}, {"group": "Reinforcement Learning", "id": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "label": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "shape": "dot", "title": "Paper: Policy Gradient Methods for Reinforcement Learning with Function Approximation\nAuthors: Unknown\nYear: Unknown\nDOI: N/A\nURL: N/A"}, {"group": "Reinforcement Learning", "id": "Function Approximation", "label": "Function Approximation", "shape": "dot", "title": "Foundational Topic: Function Approximation\nResource: Neural Networks for Pattern Recognition by Christopher M. Bishop"}, {"group": "Reinforcement Learning", "id": "Trust Region Policy Optimization", "label": "Trust Region Policy Optimization", "shape": "dot", "title": "Paper: Trust Region Policy Optimization\nAuthors: Unknown\nYear: Unknown\nDOI: N/A\nURL: N/A"}, {"group": "Reinforcement Learning", "id": "Linear Algebra", "label": "Linear Algebra", "shape": "dot", "title": "Foundational Topic: Linear Algebra\nResource: Linear Algebra and Its Applications by Gilbert Strang"}, {"group": "Reinforcement Learning", "id": "Calculus", "label": "Calculus", "shape": "dot", "title": "Foundational Topic: Calculus\nResource: Calculus: Early Transcendentals by James Stewart"}, {"group": "Reinforcement Learning", "id": "A Survey of Reinforcement Learning Algorithms", "label": "A Survey of Reinforcement Learning Algorithms", "shape": "dot", "title": "Paper: A Survey of Reinforcement Learning Algorithms\nAuthors: Unknown\nYear: Unknown\nDOI: N/A\nURL: N/A"}, {"group": "Robotics", "id": "Robotics", "label": "Robotics", "shape": "dot", "title": "Core Concept: Robotics"}, {"group": "Robotics", "id": "Programming by Demonstration: A Method for Robot Programming", "label": "Programming by Demonstration: A Method for Robot Programming", "shape": "dot", "title": "Paper: Programming by Demonstration: A Method for Robot Programming\nAuthors: Unknown\nYear: Unknown\nDOI: N/A\nURL: N/A"}, {"group": "Robotics", "id": "Human-Robot Interaction", "label": "Human-Robot Interaction", "shape": "dot", "title": "Foundational Topic: Human-Robot Interaction\nResource: Human-Robot Interaction: An Introduction by Christoph Bartneck, Tony Belpaeme, Friederike Eyssel, Takayuki Kanda, Merel Keijsers, and Selma \u0160abanovi\u0107"}, {"group": "Robotics", "id": "Computer Vision", "label": "Computer Vision", "shape": "dot", "title": "Foundational Topic: Computer Vision\nResource: Computer Vision: Algorithms and Applications by Richard Szeliski"}, {"group": "Robotics", "id": "Sensor Integration", "label": "Sensor Integration", "shape": "dot", "title": "Foundational Topic: Sensor Integration\nResource: Sensor Fusion and Integration for Intelligent Systems by S. Sitharama Iyengar and Laxmikant V. Kal\u00e9"}, {"group": "Robotics", "id": "Data Processing and Analysis", "label": "Data Processing and Analysis", "shape": "dot", "title": "Foundational Topic: Data Processing and Analysis\nResource: Data Mining: Concepts and Techniques by Jiawei Han, Micheline Kamber, and Jian Pei"}, {"group": "Robotics", "id": "Learning from Demonstration", "label": "Learning from Demonstration", "shape": "dot", "title": "Paper: Learning from Demonstration\nAuthors: Unknown\nYear: Unknown\nDOI: N/A\nURL: N/A"}, {"group": "Robotics", "id": "Imitation Learning", "label": "Imitation Learning", "shape": "dot", "title": "Foundational Topic: Imitation Learning\nResource: A Survey of Imitation Learning and its Challenges by Hussein, M., Gaber, M. M., Elyan, E., \u0026 Jayne, C."}, {"group": "Robotics", "id": "Data Collection and Preprocessing", "label": "Data Collection and Preprocessing", "shape": "dot", "title": "Foundational Topic: Data Collection and Preprocessing\nResource: Data Preparation for Data Mining by Dorian Pyle"}, {"group": "Robotics", "id": "Robot Learning from Demonstration", "label": "Robot Learning from Demonstration", "shape": "dot", "title": "Paper: Robot Learning from Demonstration\nAuthors: Unknown\nYear: Unknown\nDOI: N/A\nURL: N/A"}]);
                  edges = new vis.DataSet([{"arrows": "to", "from": "Robotic Manipulation in Unstructured Environments", "to": "Reinforcement Learning"}, {"arrows": "to", "from": "Robotic Manipulation in Unstructured Environments", "to": "Robotics"}, {"arrows": "to", "from": "Reinforcement Learning", "to": "Reinforcement Learning: An Introduction"}, {"arrows": "to", "from": "Reinforcement Learning", "to": "Human-level control through deep reinforcement learning"}, {"arrows": "to", "from": "Reinforcement Learning", "to": "Asynchronous Methods for Deep Reinforcement Learning"}, {"arrows": "to", "from": "Reinforcement Learning", "to": "Proximal Policy Optimization Algorithms"}, {"arrows": "to", "from": "Reinforcement Learning", "to": "Playing Atari with Deep Reinforcement Learning"}, {"arrows": "to", "from": "Reinforcement Learning", "to": "Policy Gradient Methods for Reinforcement Learning with Function Approximation"}, {"arrows": "to", "from": "Reinforcement Learning", "to": "Trust Region Policy Optimization"}, {"arrows": "to", "from": "Reinforcement Learning", "to": "A Survey of Reinforcement Learning Algorithms"}, {"arrows": "to", "from": "Reinforcement Learning: An Introduction", "to": "Machine Learning Basics"}, {"arrows": "to", "from": "Reinforcement Learning: An Introduction", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Reinforcement Learning: An Introduction", "to": "Control Theory"}, {"arrows": "to", "from": "Reinforcement Learning: An Introduction", "to": "Probability Theory"}, {"arrows": "to", "from": "Reinforcement Learning: An Introduction", "to": "Markov Decision Processes"}, {"arrows": "to", "from": "Reinforcement Learning: An Introduction", "to": "Dynamic Programming"}, {"arrows": "to", "from": "Reinforcement Learning: An Introduction", "to": "Stochastic Processes"}, {"arrows": "to", "from": "Reinforcement Learning: An Introduction", "to": "Optimization"}, {"arrows": "to", "from": "Human-level control through deep reinforcement learning", "to": "Machine Learning Basics"}, {"arrows": "to", "from": "Human-level control through deep reinforcement learning", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Human-level control through deep reinforcement learning", "to": "Control Theory"}, {"arrows": "to", "from": "Human-level control through deep reinforcement learning", "to": "Deep Learning"}, {"arrows": "to", "from": "Human-level control through deep reinforcement learning", "to": "Reinforcement Learning"}, {"arrows": "to", "from": "Human-level control through deep reinforcement learning", "to": "Neural Networks"}, {"arrows": "to", "from": "Human-level control through deep reinforcement learning", "to": "Optimization Algorithms"}, {"arrows": "to", "from": "Human-level control through deep reinforcement learning", "to": "Markov Decision Processes"}, {"arrows": "to", "from": "Human-level control through deep reinforcement learning", "to": "Game Theory"}, {"arrows": "to", "from": "Asynchronous Methods for Deep Reinforcement Learning", "to": "Machine Learning Basics"}, {"arrows": "to", "from": "Asynchronous Methods for Deep Reinforcement Learning", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Asynchronous Methods for Deep Reinforcement Learning", "to": "Control Theory"}, {"arrows": "to", "from": "Asynchronous Methods for Deep Reinforcement Learning", "to": "Reinforcement Learning"}, {"arrows": "to", "from": "Asynchronous Methods for Deep Reinforcement Learning", "to": "Deep Learning"}, {"arrows": "to", "from": "Asynchronous Methods for Deep Reinforcement Learning", "to": "Optimization Algorithms"}, {"arrows": "to", "from": "Asynchronous Methods for Deep Reinforcement Learning", "to": "Parallel Computing"}, {"arrows": "to", "from": "Asynchronous Methods for Deep Reinforcement Learning", "to": "Markov Decision Processes"}, {"arrows": "to", "from": "Proximal Policy Optimization Algorithms", "to": "Machine Learning Basics"}, {"arrows": "to", "from": "Proximal Policy Optimization Algorithms", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Proximal Policy Optimization Algorithms", "to": "Control Theory"}, {"arrows": "to", "from": "Proximal Policy Optimization Algorithms", "to": "Reinforcement Learning"}, {"arrows": "to", "from": "Proximal Policy Optimization Algorithms", "to": "Optimization Algorithms"}, {"arrows": "to", "from": "Proximal Policy Optimization Algorithms", "to": "Probability and Statistics"}, {"arrows": "to", "from": "Proximal Policy Optimization Algorithms", "to": "Neural Networks"}, {"arrows": "to", "from": "Proximal Policy Optimization Algorithms", "to": "Gradient Descent"}, {"arrows": "to", "from": "Proximal Policy Optimization Algorithms", "to": "Policy Gradient Methods"}, {"arrows": "to", "from": "Playing Atari with Deep Reinforcement Learning", "to": "Machine Learning Basics"}, {"arrows": "to", "from": "Playing Atari with Deep Reinforcement Learning", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Playing Atari with Deep Reinforcement Learning", "to": "Control Theory"}, {"arrows": "to", "from": "Playing Atari with Deep Reinforcement Learning", "to": "Reinforcement Learning"}, {"arrows": "to", "from": "Playing Atari with Deep Reinforcement Learning", "to": "Deep Learning"}, {"arrows": "to", "from": "Playing Atari with Deep Reinforcement Learning", "to": "Neural Networks"}, {"arrows": "to", "from": "Playing Atari with Deep Reinforcement Learning", "to": "Markov Decision Processes"}, {"arrows": "to", "from": "Playing Atari with Deep Reinforcement Learning", "to": "Q-Learning"}, {"arrows": "to", "from": "Playing Atari with Deep Reinforcement Learning", "to": "Stochastic Processes"}, {"arrows": "to", "from": "Playing Atari with Deep Reinforcement Learning", "to": "Optimization Techniques"}, {"arrows": "to", "from": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "to": "Machine Learning Basics"}, {"arrows": "to", "from": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "to": "Control Theory"}, {"arrows": "to", "from": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "to": "Reinforcement Learning"}, {"arrows": "to", "from": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "to": "Policy Gradient Methods"}, {"arrows": "to", "from": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "to": "Function Approximation"}, {"arrows": "to", "from": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "to": "Stochastic Processes"}, {"arrows": "to", "from": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "to": "Optimization Techniques"}, {"arrows": "to", "from": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "to": "Markov Decision Processes"}, {"arrows": "to", "from": "Trust Region Policy Optimization", "to": "Machine Learning Basics"}, {"arrows": "to", "from": "Trust Region Policy Optimization", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Trust Region Policy Optimization", "to": "Control Theory"}, {"arrows": "to", "from": "Trust Region Policy Optimization", "to": "Reinforcement Learning"}, {"arrows": "to", "from": "Trust Region Policy Optimization", "to": "Optimization Techniques"}, {"arrows": "to", "from": "Trust Region Policy Optimization", "to": "Probability and Statistics"}, {"arrows": "to", "from": "Trust Region Policy Optimization", "to": "Linear Algebra"}, {"arrows": "to", "from": "Trust Region Policy Optimization", "to": "Calculus"}, {"arrows": "to", "from": "Trust Region Policy Optimization", "to": "Markov Decision Processes"}, {"arrows": "to", "from": "Trust Region Policy Optimization", "to": "Policy Gradient Methods"}, {"arrows": "to", "from": "A Survey of Reinforcement Learning Algorithms", "to": "Machine Learning Basics"}, {"arrows": "to", "from": "A Survey of Reinforcement Learning Algorithms", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "A Survey of Reinforcement Learning Algorithms", "to": "Control Theory"}, {"arrows": "to", "from": "A Survey of Reinforcement Learning Algorithms", "to": "Probability and Statistics"}, {"arrows": "to", "from": "A Survey of Reinforcement Learning Algorithms", "to": "Markov Decision Processes"}, {"arrows": "to", "from": "A Survey of Reinforcement Learning Algorithms", "to": "Dynamic Programming"}, {"arrows": "to", "from": "A Survey of Reinforcement Learning Algorithms", "to": "Optimization Techniques"}, {"arrows": "to", "from": "Robotics", "to": "Programming by Demonstration: A Method for Robot Programming"}, {"arrows": "to", "from": "Robotics", "to": "Learning from Demonstration"}, {"arrows": "to", "from": "Robotics", "to": "Robot Learning from Demonstration"}, {"arrows": "to", "from": "Programming by Demonstration: A Method for Robot Programming", "to": "Machine Learning Basics"}, {"arrows": "to", "from": "Programming by Demonstration: A Method for Robot Programming", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Programming by Demonstration: A Method for Robot Programming", "to": "Control Theory"}, {"arrows": "to", "from": "Programming by Demonstration: A Method for Robot Programming", "to": "Human-Robot Interaction"}, {"arrows": "to", "from": "Programming by Demonstration: A Method for Robot Programming", "to": "Computer Vision"}, {"arrows": "to", "from": "Programming by Demonstration: A Method for Robot Programming", "to": "Sensor Integration"}, {"arrows": "to", "from": "Programming by Demonstration: A Method for Robot Programming", "to": "Data Processing and Analysis"}, {"arrows": "to", "from": "Learning from Demonstration", "to": "Machine Learning Basics"}, {"arrows": "to", "from": "Learning from Demonstration", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Learning from Demonstration", "to": "Control Theory"}, {"arrows": "to", "from": "Learning from Demonstration", "to": "Reinforcement Learning"}, {"arrows": "to", "from": "Learning from Demonstration", "to": "Human-Robot Interaction"}, {"arrows": "to", "from": "Learning from Demonstration", "to": "Imitation Learning"}, {"arrows": "to", "from": "Learning from Demonstration", "to": "Data Collection and Preprocessing"}, {"arrows": "to", "from": "Learning from Demonstration", "to": "Optimization Techniques"}, {"arrows": "to", "from": "Robot Learning from Demonstration", "to": "Machine Learning Basics"}, {"arrows": "to", "from": "Robot Learning from Demonstration", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Robot Learning from Demonstration", "to": "Control Theory"}, {"arrows": "to", "from": "Robot Learning from Demonstration", "to": "Reinforcement Learning"}, {"arrows": "to", "from": "Robot Learning from Demonstration", "to": "Human-Robot Interaction"}, {"arrows": "to", "from": "Robot Learning from Demonstration", "to": "Imitation Learning"}, {"arrows": "to", "from": "Robot Learning from Demonstration", "to": "Data Collection and Preprocessing"}, {"arrows": "to", "from": "Robot Learning from Demonstration", "to": "Optimization Techniques"}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {"layout": {"hierarchical": {"enabled": true, "direction": "UD", "sortMethod": "directed", "nodeSpacing": 200, "treeSpacing": 100}}, "nodes": {"font": {"multi": true, "size": 10}, "size": 15, "shape": "box", "widthConstraint": {"maximum": 200}}, "interaction": {"hover": true, "dragNodes": true, "selectConnectedEdges": false}, "physics": {"enabled": false, "stabilization": {"enabled": true}, "solver": "forceAtlas2Based", "forceAtlas2Based": {"gravitationalConstant": -50, "centralGravity": 0.01, "springLength": 100, "springConstant": 0.08}, "minVelocity": 0.75}};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>