<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 600px;
                 background-color: #ffffff;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             

             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"group": "project_title", "id": "Robotic Manipulation in Unstructured Environments", "label": "Robotic Manipulation in Unstructured Environments", "shape": "dot", "title": "Project Title"}, {"group": "core_concept", "id": "Reinforcement Learning", "label": "Reinforcement Learning", "shape": "dot", "title": "Core Concept"}, {"group": "seminal_paper", "id": "Reinforcement Learning: An Introduction", "label": "Reinforcement Learning: An Introduction", "shape": "dot", "title": "Seminal Paper"}, {"group": "foundational_topic", "id": "Machine Learning", "label": "Machine Learning", "shape": "dot", "title": "Foundational Topic\nResource: Pattern Recognition and Machine Learning by Christopher M. Bishop"}, {"group": "foundational_topic", "id": "Robotic Kinematics", "label": "Robotic Kinematics", "shape": "dot", "title": "Foundational Topic\nResource: Introduction to Robotics: Mechanics and Control by John J. Craig"}, {"group": "foundational_topic", "id": "Control Theory", "label": "Control Theory", "shape": "dot", "title": "Foundational Topic\nResource: Feedback Control of Dynamic Systems by Gene F. Franklin, J. Da Powell, and Abbas Emami-Naeini"}, {"group": "foundational_topic", "id": "Deep Learning", "label": "Deep Learning", "shape": "dot", "title": "Foundational Topic\nResource: Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville"}, {"group": "foundational_topic", "id": "Probability Theory", "label": "Probability Theory", "shape": "dot", "title": "Foundational Topic\nResource: Probability and Statistics by Morris H. DeGroot and Mark J. Schervish"}, {"group": "foundational_topic", "id": "Optimization", "label": "Optimization", "shape": "dot", "title": "Foundational Topic\nResource: Convex Optimization by Stephen Boyd and Lieven Vandenberghe"}, {"group": "seminal_paper", "id": "Asynchronous Methods for Deep Reinforcement Learning", "label": "Asynchronous Methods for Deep Reinforcement Learning", "shape": "dot", "title": "Seminal Paper"}, {"group": "foundational_topic", "id": "Stochastic Processes", "label": "Stochastic Processes", "shape": "dot", "title": "Foundational Topic\nResource: Introduction to Stochastic Processes by Gregory F. Lawler"}, {"group": "seminal_paper", "id": "Human-level control through deep reinforcement learning", "label": "Human-level control through deep reinforcement learning", "shape": "dot", "title": "Seminal Paper"}, {"group": "foundational_topic", "id": "Neuroscience", "label": "Neuroscience", "shape": "dot", "title": "Foundational Topic\nResource: Principles of Neural Science by Eric R. Kandel, James H. Schwartz, and Thomas M. Jessell"}, {"group": "seminal_paper", "id": "Proximal Policy Optimization Algorithms", "label": "Proximal Policy Optimization Algorithms", "shape": "dot", "title": "Seminal Paper"}, {"group": "seminal_paper", "id": "A Survey of Reinforcement Learning Algorithms", "label": "A Survey of Reinforcement Learning Algorithms", "shape": "dot", "title": "Seminal Paper"}, {"group": "seminal_paper", "id": "Playing Atari with Deep Reinforcement Learning", "label": "Playing Atari with Deep Reinforcement Learning", "shape": "dot", "title": "Seminal Paper"}, {"group": "foundational_topic", "id": "Neural Networks", "label": "Neural Networks", "shape": "dot", "title": "Foundational Topic\nResource: Neural Networks and Learning Machines by Simon Haykin"}, {"group": "foundational_topic", "id": "Optimization Methods", "label": "Optimization Methods", "shape": "dot", "title": "Foundational Topic\nResource: Convex Optimization by Stephen Boyd and Lieven Vandenberghe"}, {"group": "seminal_paper", "id": "Deep Reinforcement Learning with Double Q-learning", "label": "Deep Reinforcement Learning with Double Q-learning", "shape": "dot", "title": "Seminal Paper"}, {"group": "foundational_topic", "id": "Optimization Theory", "label": "Optimization Theory", "shape": "dot", "title": "Foundational Topic\nResource: Convex Optimization by Stephen Boyd and Lieven Vandenberghe"}, {"group": "core_concept", "id": "Robotics", "label": "Robotics", "shape": "dot", "title": "Core Concept"}, {"group": "seminal_paper", "id": "Learning for Robotic Manipulation", "label": "Learning for Robotic Manipulation", "shape": "dot", "title": "Seminal Paper"}, {"group": "foundational_topic", "id": "Computer Vision", "label": "Computer Vision", "shape": "dot", "title": "Foundational Topic\nResource: Computer Vision: Algorithms and Applications by Richard Szeliski"}, {"group": "seminal_paper", "id": "Advances in Robotic Manipulation", "label": "Advances in Robotic Manipulation", "shape": "dot", "title": "Seminal Paper"}, {"group": "seminal_paper", "id": "Deep Learning for Robot Learning from Demonstration", "label": "Deep Learning for Robot Learning from Demonstration", "shape": "dot", "title": "Seminal Paper"}, {"group": "seminal_paper", "id": "Robot Learning from Demonstration", "label": "Robot Learning from Demonstration", "shape": "dot", "title": "Seminal Paper"}, {"group": "foundational_topic", "id": "Probabilistic Models", "label": "Probabilistic Models", "shape": "dot", "title": "Foundational Topic\nResource: Probabilistic Graphical Models: Principles and Techniques by Daphne Koller and Nir Friedman"}, {"group": "seminal_paper", "id": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "label": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "shape": "dot", "title": "Seminal Paper"}]);
                  edges = new vis.DataSet([{"arrows": "to", "from": "Robotic Manipulation in Unstructured Environments", "to": "Reinforcement Learning"}, {"arrows": "to", "from": "Robotic Manipulation in Unstructured Environments", "to": "Robotics"}, {"arrows": "to", "from": "Reinforcement Learning", "to": "Reinforcement Learning: An Introduction"}, {"arrows": "to", "from": "Reinforcement Learning", "to": "Asynchronous Methods for Deep Reinforcement Learning"}, {"arrows": "to", "from": "Reinforcement Learning", "to": "Human-level control through deep reinforcement learning"}, {"arrows": "to", "from": "Reinforcement Learning", "to": "Proximal Policy Optimization Algorithms"}, {"arrows": "to", "from": "Reinforcement Learning", "to": "A Survey of Reinforcement Learning Algorithms"}, {"arrows": "to", "from": "Reinforcement Learning", "to": "Playing Atari with Deep Reinforcement Learning"}, {"arrows": "to", "from": "Reinforcement Learning", "to": "Deep Reinforcement Learning with Double Q-learning"}, {"arrows": "to", "from": "Reinforcement Learning: An Introduction", "to": "Machine Learning"}, {"arrows": "to", "from": "Reinforcement Learning: An Introduction", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Reinforcement Learning: An Introduction", "to": "Control Theory"}, {"arrows": "to", "from": "Reinforcement Learning: An Introduction", "to": "Deep Learning"}, {"arrows": "to", "from": "Reinforcement Learning: An Introduction", "to": "Probability Theory"}, {"arrows": "to", "from": "Reinforcement Learning: An Introduction", "to": "Optimization"}, {"arrows": "to", "from": "Asynchronous Methods for Deep Reinforcement Learning", "to": "Machine Learning"}, {"arrows": "to", "from": "Asynchronous Methods for Deep Reinforcement Learning", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Asynchronous Methods for Deep Reinforcement Learning", "to": "Deep Learning"}, {"arrows": "to", "from": "Asynchronous Methods for Deep Reinforcement Learning", "to": "Control Theory"}, {"arrows": "to", "from": "Asynchronous Methods for Deep Reinforcement Learning", "to": "Optimization"}, {"arrows": "to", "from": "Asynchronous Methods for Deep Reinforcement Learning", "to": "Stochastic Processes"}, {"arrows": "to", "from": "Human-level control through deep reinforcement learning", "to": "Machine Learning"}, {"arrows": "to", "from": "Human-level control through deep reinforcement learning", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Human-level control through deep reinforcement learning", "to": "Deep Learning"}, {"arrows": "to", "from": "Human-level control through deep reinforcement learning", "to": "Control Theory"}, {"arrows": "to", "from": "Human-level control through deep reinforcement learning", "to": "Neuroscience"}, {"arrows": "to", "from": "Human-level control through deep reinforcement learning", "to": "Optimization"}, {"arrows": "to", "from": "Proximal Policy Optimization Algorithms", "to": "Machine Learning"}, {"arrows": "to", "from": "Proximal Policy Optimization Algorithms", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Proximal Policy Optimization Algorithms", "to": "Deep Learning"}, {"arrows": "to", "from": "Proximal Policy Optimization Algorithms", "to": "Control Theory"}, {"arrows": "to", "from": "Proximal Policy Optimization Algorithms", "to": "Optimization"}, {"arrows": "to", "from": "Proximal Policy Optimization Algorithms", "to": "Probability Theory"}, {"arrows": "to", "from": "A Survey of Reinforcement Learning Algorithms", "to": "Machine Learning"}, {"arrows": "to", "from": "A Survey of Reinforcement Learning Algorithms", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "A Survey of Reinforcement Learning Algorithms", "to": "Deep Learning"}, {"arrows": "to", "from": "A Survey of Reinforcement Learning Algorithms", "to": "Control Theory"}, {"arrows": "to", "from": "A Survey of Reinforcement Learning Algorithms", "to": "Probability Theory"}, {"arrows": "to", "from": "A Survey of Reinforcement Learning Algorithms", "to": "Optimization"}, {"arrows": "to", "from": "Playing Atari with Deep Reinforcement Learning", "to": "Machine Learning"}, {"arrows": "to", "from": "Playing Atari with Deep Reinforcement Learning", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Playing Atari with Deep Reinforcement Learning", "to": "Deep Learning"}, {"arrows": "to", "from": "Playing Atari with Deep Reinforcement Learning", "to": "Control Theory"}, {"arrows": "to", "from": "Playing Atari with Deep Reinforcement Learning", "to": "Neural Networks"}, {"arrows": "to", "from": "Playing Atari with Deep Reinforcement Learning", "to": "Optimization Methods"}, {"arrows": "to", "from": "Playing Atari with Deep Reinforcement Learning", "to": "Probability Theory"}, {"arrows": "to", "from": "Deep Reinforcement Learning with Double Q-learning", "to": "Machine Learning"}, {"arrows": "to", "from": "Deep Reinforcement Learning with Double Q-learning", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Deep Reinforcement Learning with Double Q-learning", "to": "Deep Learning"}, {"arrows": "to", "from": "Deep Reinforcement Learning with Double Q-learning", "to": "Control Theory"}, {"arrows": "to", "from": "Deep Reinforcement Learning with Double Q-learning", "to": "Optimization Theory"}, {"arrows": "to", "from": "Deep Reinforcement Learning with Double Q-learning", "to": "Probability Theory"}, {"arrows": "to", "from": "Robotics", "to": "Reinforcement Learning: An Introduction"}, {"arrows": "to", "from": "Robotics", "to": "Learning for Robotic Manipulation"}, {"arrows": "to", "from": "Robotics", "to": "Advances in Robotic Manipulation"}, {"arrows": "to", "from": "Robotics", "to": "Deep Learning for Robot Learning from Demonstration"}, {"arrows": "to", "from": "Robotics", "to": "Robot Learning from Demonstration"}, {"arrows": "to", "from": "Robotics", "to": "Policy Gradient Methods for Reinforcement Learning with Function Approximation"}, {"arrows": "to", "from": "Robotics", "to": "Proximal Policy Optimization Algorithms"}, {"arrows": "to", "from": "Learning for Robotic Manipulation", "to": "Machine Learning"}, {"arrows": "to", "from": "Learning for Robotic Manipulation", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Learning for Robotic Manipulation", "to": "Deep Learning"}, {"arrows": "to", "from": "Learning for Robotic Manipulation", "to": "Control Theory"}, {"arrows": "to", "from": "Learning for Robotic Manipulation", "to": "Optimization"}, {"arrows": "to", "from": "Learning for Robotic Manipulation", "to": "Computer Vision"}, {"arrows": "to", "from": "Advances in Robotic Manipulation", "to": "Machine Learning"}, {"arrows": "to", "from": "Advances in Robotic Manipulation", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Advances in Robotic Manipulation", "to": "Control Theory"}, {"arrows": "to", "from": "Advances in Robotic Manipulation", "to": "Deep Learning"}, {"arrows": "to", "from": "Advances in Robotic Manipulation", "to": "Computer Vision"}, {"arrows": "to", "from": "Advances in Robotic Manipulation", "to": "Optimization"}, {"arrows": "to", "from": "Deep Learning for Robot Learning from Demonstration", "to": "Machine Learning"}, {"arrows": "to", "from": "Deep Learning for Robot Learning from Demonstration", "to": "Deep Learning"}, {"arrows": "to", "from": "Deep Learning for Robot Learning from Demonstration", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Deep Learning for Robot Learning from Demonstration", "to": "Control Theory"}, {"arrows": "to", "from": "Deep Learning for Robot Learning from Demonstration", "to": "Computer Vision"}, {"arrows": "to", "from": "Deep Learning for Robot Learning from Demonstration", "to": "Optimization"}, {"arrows": "to", "from": "Robot Learning from Demonstration", "to": "Machine Learning"}, {"arrows": "to", "from": "Robot Learning from Demonstration", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Robot Learning from Demonstration", "to": "Control Theory"}, {"arrows": "to", "from": "Robot Learning from Demonstration", "to": "Deep Learning"}, {"arrows": "to", "from": "Robot Learning from Demonstration", "to": "Probabilistic Models"}, {"arrows": "to", "from": "Robot Learning from Demonstration", "to": "Optimization"}, {"arrows": "to", "from": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "to": "Machine Learning"}, {"arrows": "to", "from": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "to": "Robotic Kinematics"}, {"arrows": "to", "from": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "to": "Deep Learning"}, {"arrows": "to", "from": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "to": "Control Theory"}, {"arrows": "to", "from": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "to": "Optimization"}, {"arrows": "to", "from": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "to": "Probability Theory"}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {"layout": {"hierarchical": {"enabled": false, "direction": "UD", "sortMethod": "directed", "nodeSpacing": 200, "treeSpacing": 300}}, "nodes": {"font": {"multi": true, "size": 20}, "size": 25, "shape": "box", "widthConstraint": {"maximum": 200}}, "interaction": {"hover": true, "dragNodes": true, "selectConnectedEdges": false}, "physics": {"enabled": true, "stabilization": {"enabled": true}, "solver": "forceAtlas2Based", "forceAtlas2Based": {"gravitationalConstant": -100, "centralGravity": 0.01, "springLength": 200, "springConstant": 0.05}, "minVelocity": 0.75}};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>